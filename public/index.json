[{"content":"High Precision Function Approximation With Decision Trees and Neural Networks While I interned at QuantCo, I worked on a kind of crazy project with my (amazing) advisor Ben Thompson, titled \u0026ldquo;The Deep Neural Net Function Approximation Project\u0026rdquo;. Here\u0026rsquo;s the problem (with sensitive information stripped):\nOne of the clients is currently migrating a system. Written in C, it comprises of a ton of data and a ton of different functions, many of which are high-dimensional and full of discontinuities. QuantCo has been tasked to help the client migrate all of that to a new system using python and onto the cloud to make it more efficient, faster, and secure. However, the client estimates it would take about 100 person-years to complete due to the complexity of the system, the immense amount of math, and the immense amount of functionality and code that need to be migrated. Luckily, QuantCo has already reduced that work to less than 1 person-year. But can we do this even faster? Could we somehow automate code migration and reduce the time even further?\nInitially, this sounds like an impossible problem. Luckily, there are a few important things to note.\nThe client doesn\u0026rsquo;t care what the migrated code is like; they simply expect that historical data plugged into the migrated functions produce the same values to within some max acceptable error. We have the old system at our disposal. We can run it whenever we want. tldr; points 1 and 2 allow us to almost automate code migration. Point 1 means we can treat it as solving a difficult regression problem. Our approach then lets us use both points to turn code into matrices with a decision tree neural net (DTNN) model that is horizontally and vertically scalable. There\u0026rsquo;s also a bunch of strange / interesting use cases ranging from security to function compression to differentiating anyone\u0026rsquo;s code (even if it doesn\u0026rsquo;t really do any math).\nNow here\u0026rsquo;s a more formal statement:\nGiven some target function $f: \\mathbb R^n \\to \\mathbb R^m$, approximate $f$ with another function $\\hat{f}$ so that $\\hat{f}(x) = \\hat{y}$ is as close as possible to the ground truth $f(x)$. You are allowed to use $f$ to generate as many noiseless $(x, y)$ samples as you would like.\nThis function $f$ in our case is actually a giant file of code.\nThe above problem statement may seem somewhat trivial and seem like a typical regression problem, but there are a lot of hidden hazards that increase the difficulty immensely.\nThe target function we\u0026rsquo;re approximating is extremely discontinuous and complicated. This arises from the fact the function will completely change behavior when certain inputs change. In our project, the target function is a super large, handwritten calculator that computes some value given some inputs. In this calculator, there are various if statements, matrix products, string manipulations, array slicing, every arithmetic operator, and even reading data from data files that contribute to the outputs.\nThis means the majority of the classical regression models and any function approximation methods will almost certainly fail at regions of discontinuity in the target function, but for our problem, we need to make sure every single data point is approximated to within 1 of its true value. Moreover, different smooth regions in the target function all behave potentially completely different (one might be $e^x$, another might be $x^2- 3|x|$ all of a sudden)\nAdditionally, the target function produces values in the range of 1e5 to 1e7, which means our function approximator needs to achieve a precision of around 1e-5 to 1e-7 to pass.\nLastly, the target function has a high input and output dimensionality, both of which are in the order of 100s. This adds difficulty for any kind of model and slows down training and decreases accuracy. Additionally, we can\u0026rsquo;t apply any kind of feature selection and / or dimensionality reduction without the potential loss of information necessary for producing accurate output values.\nIn a nutshell, we solve a difficult regression problem, but there are a number of quirks in our case, namely\nWe have an oracle $f$​ (also our target function) that can generate noiseless groundtruth $(x, y)$​​ pairs on the fly. $f$​ is extremely discontinuous and changes a ton around discontinuities We need to achieve a high degree of precision on the orders of 1e-5 to 1e-7 $f$ also has 100s of dimensions in its input and output spaces Because of these quirks, many approaches have been investigated, and I\u0026rsquo;ll go in depth in the following 4\nNeural Networks 2nd order optimization of Neural Nets for regression Residual-based splitting Decision Trees + Neural Nets (DTNN) These proved to be the most influential and powerful methods out of all the other tricks and techniques we experimented with.\nNeural Networks Why deep neural nets for an approximation problem?\nIf we first consider the naive approach of storing a bunch of pre-computed pairs $(x, f(x))$​​ for all $x$ values in the historical data, we would have a perfect approximator. However, there not only is a ton of historical data (likely on the scale of petabytes), using this as a function to then retrieve a value for a given $x$​​ would take an unreasonably long time. Supposing you used some kind of nearest neighbor weighting model and stored a fraction of the historical data values and reduced the search time to find the $k$ nearest data points necessary for interpolation to reasonable milliseconds, then the accuracy worsens significantly.\nNow suppose we first ignore the discontinuities in our target function, we otherwise have very little information about what the target function is like without having to dive deep into the function\u0026rsquo;s code itself or doing significant data analysis on an extremely complex function. So most attempts to tackle this like a data science problem end up failing here. We need something that is flexible and can capture almost arbitrary patterns in the data.\nLuckily, since the client only cares that all historical data when passed through the approximated function are correct, we don\u0026rsquo;t need to worry about extrapolation, so potentially interpolation algorithms can come into play. We could generate many interpolation points and use interpolation algorithms such as polynomial interpolation, which in fact get really good approximations. Unfortunately, interpolation algorithms cannot scale when the dimensions increase and they begin to have impossible memory requirements after about as little as 5 dimensions for our particular target function. Trading off accuracy for lower memory requirements is also unfortunately very poor.\nDeep neural nets on the other hand are flexible function approximators and scale much better with dimensions in terms of both memory and compute, and arguably compress information much better than the interpolation algorithms at the cost of spending time training.\nThe typical way to use neural nets in a regression problem is to train the neural net over a lot of training data, constantly evaluate it on a held-out validation dataset and select the model that achieves the lowest loss on the validation dataset. In particular, the loss function is the MSE loss function and the optimizer that worked best was Adam. I won\u0026rsquo;t explain much in detail here, but tanh activation turns out to be the best and outperforms any non-smooth activation like ReLU significantly.\nHowever, standard neural networks on their own are nowhere near sufficient to achieve any level of desirable accuracy in our project, and the next section discusses the first massive improvement in performance via 2nd order optimization.\n2nd Order Optimization Almost ubiquitously, deep learning practitioners rely on first-order optimization algorithms such as Gradient Descent, Adam, RMSProp to name a few. These methods prove incredibly useful in many tasks because they are fast, computationally efficient and feasible, often bug-free, and many other reasons listed out in this stackoverflow answer. Another important aspect of first-order methods is that they achieve low generalization error compared to second-order methods, making algorithms like SGD and Adam incredibly popular in CV and NLP tasks where generalization error is paramount.\nHowever, some of these aspects are not a problem in our project. Generalization error is less of an issue since we can generate infinite, noiseless data, with the same distribution as test data, and in fact we can control the generalization error by tuning how much data is fed to the model at training time. In a future section when I discuss about the DTNN model, we also don\u0026rsquo;t need as much data as you think to be generated to ensure low generalization error. For similar reasons, in the DTNN model the neural networks trained are generally quite small, so we don\u0026rsquo;t have an issue of scale faced by 2nd order optimization of large neural networks.\nThese features of our project suddenly make 2nd order optimization algorithms much more feasible. Since we want to achieve an extremely high level of precision, 2nd order optimization actually becomes necessary.\nL-BFGS proves to be a very capable and feasible 2nd order algorithm that ended up being used throughout this entire project. The following graph shows as a function of time (s), how L-BFGS compares to Adam, a 1st order method when trying to fit the function $\\cos(20x)$​ over $x \\in [-1, 1]$ with a small neural network (~40 parameters). The data generated and fed into the neural network mimics that of the actual project. Very quickly L-BFGS converges to a low loss and outperforms Adam considerably.\nWith 2nd order optimization, a single deep neural net was able to achieve about 30% accuracy on test data in the project, meaning it predicted 30% of data points to within 1 of its true value. But this is about as far as it will go, and can\u0026rsquo;t scale farther in any direction (model complexity, time, data etc.) without entering scaling problems or hitting a minimum. The major issue is that discontinuities reduce the performance of the neural net as it attempts to fit a smooth model over it, in addition to having major approximation errors around the discontinuities. I tackle this issue next.\nResidual-Based Splitting\u0026quot;\u0026gt;Residual-Based Splitting We can treat any arbitrary function like our target function as being some piecewise smooth function if you split the input space into the right regions. So one solution is to identify the smooth regions of the input space and train a different function approximator that can achieve high precision and doesn\u0026rsquo;t need to worry about fitting to discontinuities. Thus, the fundamental reason for using a Decision Tree for this problem is to handle discontinuities.\nBefore diving into how a DT and NN work together, let\u0026rsquo;s first look at the splitting algorithm that drives it.\nTo understand how the splitting works to find discontinuities, I\u0026rsquo;ll demonstrate it on a simple one-dimensional discontinuous sine dataset which is shown below.\nThere\u0026rsquo;s a clear jump discontinuity at around x = 56 which would cause regression to be difficult! But let\u0026rsquo;s do a bit of overkill and try fitting a tanh activated neural network with L-BFGS to this data, we generate the following predictions (orange) compared to the ground truth (blue)\nNotably, we observe that on the smooth parts of the dataset, the neural network more or less fits it well. However, as we approach the discontinuity the predictions begin to vary a lot and we can see that the neural net attempts to make a smooth connection between the start and end of a discontinuity. Visually it\u0026rsquo;s clear where the discontinuity is, and we can identify this algorithmically by using residuals, which is equal to prediction - ground_truth, and when we plot the residuals we get\nThe residuals are a strong signal of where the model has fitted well and where it hasn\u0026rsquo;t. We can see that the residual magnitude is near 0 on smooth parts, and increases significantly near the discontinuity. We can then clean up this signal further by taking the top 99th percentile of residuals by magnitude, leaving us with the following data points. The red dashed line represents the location of the true discontinuity.\nWe observe now that amongst the largest residuals, residuals increase in magnitude in the negative direction as we approach the discontinuity before suddenly flipping in sign and decreasing in magnitude as we move away from the discontinuity. This is something that will often happen when fitting smooth models like a neural network with smooth activation to the discontinuity as the model attempts to find a smooth transition around the discontinuity. However, as a result, the residuals will have a sign flip and / or a large increase in magnitude around the discontinuity.\nA direct algorithmic way to then find this discontinuity is to use the splitting algorithm regression DTs use, which is finding a split on one of the input dimensions that minimizes the mean squared error of the 99th percentile residuals. Visibly, we can see that such a split would minimize the MSE by splitting near the discontinuity. This serves as a rather crude (but surprisingly effective) approach to identifying residuals with minimal overhead.\nThere can be a lot of further research on discontinuity finding to improve this, from refining a split decided by a DT by generating more data near the split or finding other algorithms that discover and can ignore the noise potentially introduced by poor-fitting in other input space regions, in addition to being more effective in higher dimensions where discontinuities in other dimensions or spanning multiple dimensions can make this much more complex.\nDTNNs Now that we have in our toolbox a neural network-based function approximator and a method to identify discontinuities and separate out the smooth regions in the input space, we can combine these into a single decision tree neural network model. This combination then allows us to also make effective use of a key property of this problem, which is that we can generate data on the fly using the target function.\nAt a high level, a DTNN is a decision tree with neural nets at each leaf that perform the regression for any data that falls to that leaf, and the splitting algorithm is the residual-based splitting method. Thanks to the splitting of the input space, we also don\u0026rsquo;t need as much data or as big of a neural network model at each leaf to sufficiently capture the behavior there with high accuracy.\nGrowing the DTNN The growing algorithm is quite similar to a typical decision tree growing algorithm but with a few changes. The DTNN maintains the same procedure of taking each leaf node and determining first whether to continue splitting, then deciding on the best split to make before making the split.\nOne key difference is that every leaf has an associated neural network that does the prediction for all data that falls into that leaf\u0026rsquo;s data range (the subset of the input space it represents). Note that each leaf is associated with a disjoint subset of the input space of the target function, and the union of all these disjoint subsets forms the entire input space (up to the boundaries set for interpolation).\nFor leaf node splitting, the residual-based splitting method introduced earlier is used and the residuals are computed using the trained neural net associated with the leaf. Importantly, since we can generate infinite data, this model can become infinitely precise to the point it memorizes every input output pair via splitting the input space into extremely data ranges. Thus, we only split leaf nodes where the neural network trained there is not accurate enough. Ideally, this neural network reduces the need to memorize every value and learns a good approximation with fewer parameters.\nFor each new leaf produced after splitting an old leaf, we create a new associated neural net. These new neural nets are copies of the neural net associated with the old leaf, helping speed up training with a warm start.\nLastly, we regenerate data in each new leaf, using randomly selected inputs data points that fall within the new leaf\u0026rsquo;s data range, and train the neural net on that new data.\nVisually, growing a DTNN looks like this:\nA green circle represents a leaf node that has a trained neural network that is accurate enough, a blue node is an internal node or a to be trained leaf node. Each round, we increase the depth of the tree by one via residual-based splitting and only generate two children per leaf node, and then fine tune the neural nets at all leaf nodes that need fine tuning.\nDTNN Pseudocode For those who prefer pseudocode, the growing algorithm is as follows\ndef DTNNGrow(rounds, train_net, data_generator, pass_criteria, splitting_func, input_subspace): root_node := initialize a DTNN with a empty root node associated with input_subspace leafs_to_train = { root_node } passing_leafs = {} for round = 1 to round = rounds: if leafs_to_train is empty: return root_node for leaf in leafs_to_train: # generate data within the subset of the input space of data that falls in the leaf train_data, test_data := data_generator(leaf.data_range) if leaf has a parent node: neural_net := copy of neural net in parent node else: neural_net := initialize a new neural net # train a NN until its good enough or until some max iterations train_net(neural_net, train_data, test_data) remove leaf from leafs_to_train if pass_criteria(neural_net, test_data): add leaf to the set passing_leafs else: # split the subspace of the current leaf based on the trained NN and train_data data_ranges := splitting_func(neural_net, train_data, leaf.data_range) for data_range in data_ranges: new_leaf := initialize a new leaf node associated with data_range add new_leaf to the set leafs_to_train return root_node We grow the DTNN in rounds, with each round increasing the depth of the DTNN by 1. To train, you provide the number of training rounds, a neural net training function, the data generator, a pass criteria function, and a splitting function.\nThe neural net training function train_net should take a neural net, training data, and test data generated from the data_generator that is within a leaf\u0026rsquo;s data range, and train that neural net. Usually, this stops training when the neural net is accurate enough, or when it is training for too long.\nThe data_generator will usually be a wrapper function around the target function we want to approximate where it takes a data range and produces training and test data that is within that data range. Our experiments used uniform sampling across each input dimension of the data range, but I actually recommend using something akin to farthest point sampling (common sampling technique in 3D computer vision like sampling point clouds).\nThe pass_criteria function will evaluate a neural net over the given test data and would return true if the neural net is good enough and false otherwise. This function is important since the data is noiseless and infinitely generatable, so theoretically you can always keep improving but we need to stop eventually.\nThe splitting_func is a function that when given the neural network, the training data, and the data range the training data is generated from, returns the new data ranges for all new leaves. An example would be the residual-based splitting method.\nThe input_subspace is simply the data range of inputs that we want to approximate the target function over, and the root node of the DTNN is associated with this input subspace. For our project, this would be the boundaries of every feature dimension in the historical data.\nDTNN Discussion Results With the DTNN and residual-based splitting and 2nd order optimization, we raised that 30% to about 86% of test data points approximated to within 1, despite data points being on the order of 1e5 to 1e7. In particular, the single NN and DTNN were both trained on a single CPU for 64 hours and achieved 30% and 86% accuracy respectively. This outperforms just about any regression model we tried, from GBDTs (~2% accuracy), to first-order optimized neural nets (~2% accuracy), to interpolation algorithms (infeasible).\nThe major reason the DTNN achieves such a massive improvement is in addition to 2nd order optimization, it also can effectively leverage the data generating aspect of the problem in an efficient distributed manner via a decision tree structure. Intuitively, each split at a leaf reduces the data range for the new leaves, meaning less data is necessary to be kept around in memory to achieve low generalization error, and effectively optimize a neural network as well. Models that can\u0026rsquo;t leverage the data generation will have to rely on generating a huge amount of data that can barely fit in memory or augmenting data every round. Even with some kind of data generation mimicking that of the DTNN where data is effectively generated for leaves that need more training / high error regions in the input space, models like single neural nets will need to not only be massive, but also somehow solve the issue of catastrophic forgetting.\nThe DTNN also has a number of nice properties. One is that it is highly scalable compared to neural networks, another is that it has unbounded performance potential with no generalization problems (usually). There are a bunch more but these are listed in the further applications section. There\u0026rsquo;s also a further research topic section that lists out a number of questions my advisor and I asked that we didn\u0026rsquo;t have time to explore but are probably worth exploring and can improve the results.\nScaling You can easily parallelize the DT growing process by training each leaf on a separate core, subject to balancing issues if there are only 2 leaves training and one takes a lot longer than the other. Moreover, this project is more often CPU bottlenecked as the target function tends to be the main limiting factor due to data generation speeds, so GPUs aren\u0026rsquo;t really necessary (nor are 2nd order optimization methods that well optimized on the GPU), so in terms of scaling, you can simply increase the number of CPUs (generally quite easy) and achieve pretty high efficiency in training speed vs number of CPUs used.\nYou can even horizontally scale this process across multiple servers probably, although I\u0026rsquo;m not exactly sure how much of an overhead that might have. I suspect it should be fairly low since the only unique data each different server has is the data range and the neural network, everything else is the same from the target function / data generator, to the neural network architecture and splitting function.\nUnbounded Potential In theory, with a target function at hand to generate noiseless training data, the DTNN can get 100% of training and test data points approximated to not just within 1, but even 0.1, 0.01, etc. when given sufficient time, a guarantee that cannot be said of any other model that I\u0026rsquo;m aware of (except for an extremely, out of memory, DT kind of model which at that point is really just memorizing the training data).\nThis is thanks to the fact that the test data will always be \u0026ldquo;in distribution\u0026rdquo; since it\u0026rsquo;s generated from the same function as the training dataset (and generally mimics the historical data the client has). As long the neural network at each leaf is given sufficient data points, it will have minimal to no generalization error.\nMoreover, every split on the data range makes training neural nets easier and easier as you effectively cut the hard part of the regression problem out and leave just the smoother regions of data. This is an easy direct way of adding parameters to the model to boost performance without making a neural network bigger and scales linearly with each leaf added.\nFurther Applications In addition to just solving the formal problem of approximating a target function with high accuracy and precision, there are a number of other applications of this since we effectively turn lines of code that form the target function into matrices! Here is a non-exhaustive list of some of these applications\nFunction compression: Reduce the amount of space required for purpose of approximation. Moreover, the calculator that was being approximated in my project actually pulls data from various tables and the neural nets are capable of removing the need for that data and bake that information into their model parameters Faster computations: speed up an existing function with a faster model that approximates it. Easily trading off accuracy for speed. Differentiation: Differentiate a handwritten function for analysis purposes. Derivative information is often useful for many problems such as optimization. My advisor had the idea of potentially trying to determine which other calculators in our client\u0026rsquo;s old system were most similar to the one we approximated and first-order information would be helpful in determining this. Portability: A decision tree and their neural networks can be easily packaged as some matrices in a single data file which can easily be run anywhere without needing access to sensitive files and data. Security: A file containing just matrices makes people very comfortable compared to a calculator with 1000s of lines of code and poses a minimal security risk should these matrices get stolen as business logic cannot be read from them. Further Research Topics We faced a number of interesting problems in an effort to approximate our target function, all of which may benefit from additional research to improve training time, accuracy etc.\nHandling discrete/continuous: Discontinuity finding may differ when the input dimension is discrete or continuous. Perhaps some kind of bisection search method may find the true discontinuity with high precision and accuracy or using some form of refinement procedure to fine tune a split on a continuous axis.\nNon-linear/non-axial discontinuities: In higher dimensions, discontinuities may not be axial and may be non-linear. While these discontinuities can sometimes be approximated by several axial/linear splits on the input data space range, there are likely more efficient methods that allow for non-linear splits that can cover a wider range of potential discontinuities. One method might be to replace the splitting function with a neural net trained to perform \u0026ldquo;split classification\u0026rdquo;. Not only does this enable non-linear splits, but it would also make the entire DTNN model end to end learnable and differentiable which could have potentially interesting results.\nData generating given non-linear/non-axial splits: Supposing the above problem was dealt with and we now have a splitting function that effectively classifies a data point as being one of k classes. How do we generate data for each of these classes?\nAdaptive data generation: When not enough data is provided for training, a model will get a high generalization error which is not desirable. However, when too much data is provided, the marginal improvement in generalization error is likely not worth the amount of extra training time required. Thus, there is probably some kind of optimal data generation amount at each leaf of the DTNN.\nAdaptive early stopping: Notably, just increasing the total number of training iterations per leaf does not necessarily correlate with a better model when training for the same total amount of time as a model can begin to struggle due to discontinuities. Empirically, too many iterations makes the model spend too much time trying to approximate discontinuities when it is better off performing a split first, then training for much longer. Can we somehow optimally determine when to perform a split to deal with discontinuities?\nClosing Notes I had a great time at QuantCo and working with my advisor on this problem. If you are ever interested in the craziest engineering, machine learning, data science, etc. problems, pay them a visit. Or if you like good company and food, they\u0026rsquo;re also a great place.\n🌊\n","permalink":"https://blog.stoneztao.com/posts/nn-fnc-approx/","summary":"High Precision Function Approximation With Decision Trees and Neural Networks While I interned at QuantCo, I worked on a kind of crazy project with my (amazing) advisor Ben Thompson, titled \u0026ldquo;The Deep Neural Net Function Approximation Project\u0026rdquo;. Here\u0026rsquo;s the problem (with sensitive information stripped):\nOne of the clients is currently migrating a system. Written in C, it comprises of a ton of data and a ton of different functions, many of which are high-dimensional and full of discontinuities.","title":"High Precision Function Approximation With Decision Trees and Neural Networks"},{"content":"A Survey of AI Programming Challenges In 2018, I got my first real taste of an AI programming challenge. It was MIT\u0026rsquo;s infamously difficult Battlecode. I competed in it with a few friends on a complete whim. I had no knowledge of Java or any algorithms/data structures and as expected we basically sucked really hard. Flopped every tournament. You would not expect someone to suddenly make finals the year after, or consecutively for 3 years in a row, to then go on to be extremely interested in AI.\nI put this up first because I dislike saying Battlecode is a bad competition because it is the very reason I\u0026rsquo;m where I am right now. I\u0026rsquo;m working at QuantCo as an intern purely because of Battlecode. I\u0026rsquo;m interested in AI because of Battlecode. I\u0026rsquo;m interested in Computer Science and Cognitive Science because of Battlecode (and a few other factors). So no hard feelings @Battlecode devs, but Battlecode still needs a lot of work and the current state unfortunately clouds all the great work Battlecode has done over the years.\nThis post provides a survey of a few competitions presented as mini case studies, pointing out what is great and what is not so great. In particular, I have selected Battlecode, Halite, Terminal, CodinGame and Screeps. These 5 (in my opinion) span the general spectrum of the current state of AI programming challenges. Lastly, I also give a overview of the Lux AI Challenge and give it a similar sort of \u0026ldquo;case study\u0026rdquo; treatment.\nIf you don\u0026rsquo;t know what an AI programming challenge is, it\u0026rsquo;s effectively programming a virtual bot to compete against other bots in a game.\nAnd tldr; My current ranking of AI challenges, weighing factors like game design, quality, tooling, and community building:\nLux AI Challenge (not biased at all) 2. Screeps 3. Halite 4. Battlecode 5. CodinGame 6. Terminal Case Studies Battlecode Here\u0026rsquo;s what Battlecode gets right. Community. Right from the start, you join a (rather niche) online community of people who love to compete in AI programming competitions, talk strategy, code, and random other things. Battlecode has built a following, an alumni network, and online community over its decades old history of existence and recently has done well to maintain that to some extent. You will literally see previous winners who now work full-time come back as company representatives for recruiting. There are also a number of blog posts online which have \u0026ldquo;cult\u0026rdquo; like following in that a ton of people read them, e.g. Cory Li\u0026rsquo;s post on bytecode optimization which proves an effective toolset to have in Battlecode. Their current president, Jerry Mao is a Battlecode alumni and I\u0026rsquo;ve had some great memories competing against his teams. Their team is great at just being active in their community and taking with competitors and are extremely down to earth!\nNow here\u0026rsquo;s what they get wrong\nAccessibility, Barriers to entry, Game Balance, Feedback, and probably 20+ more design principles broken according to \u0026ldquo;The Design of Everyday Things\u0026rdquo; (here on out abbreviated as DOET) by Don Norman (a truly in-depth, fascinating, relevant, meaningful book)\nWhat causes this? A decade-something-old JVM based engine that only allows bots written in Java to compete. A disregard for their competitor\u0026rsquo;s time (or just lack of development man power on Battlecode\u0026rsquo;s team). Lots of last minute patches here and there. A seriously poorly optimized visualizer. And a general lack of proper \u0026ldquo;design thinking\u0026rdquo; and design process.\nNote that the above should be taken with a grain of salt in the sense that it depends on what goal you think one should strive for when building AI competitions. I recently had a chat with Jerry Mao himself over a call and to be fair, when he explains how Battlecode is approaching their competition, it sounds quite normal and reasonable. Battlecode really does well to hit a specific niche of competitors, but my view is that it should be more accessible instead of making it fun for the few, so I continue my small discussion on the issues.\nDesigning a competition is incredibly difficult, and you cannot blame anyone for not coming with a interesting game design. Battlecode has a great history of designing super fun game designs, but a bad history of repeatedly changing the game mid way through a one month competition with week by week high stakes intermediate competitions. A consequence of their approach to build competition designs is that they tend to create super long matches, which make it difficult for competitors to develop their agents as feedback on bot performance is extremely delayed.\nOn the side of engineering, so much more could be done. Seriously, the engine they\u0026rsquo;re using is the same thing they\u0026rsquo;ve been relying on in the last decade. A Catalan based AI competition built by some members from the Battlecode community, while smaller in popularity, have a much faster JVM based engine with supposedly minor tweaks. Another limiting factor is that Battlecode will not move away from bytecode counting computation caps, which are quite confusing to newcomers and you have to rely on tedious hyper-optimizations on bytecode which really isn\u0026rsquo;t that fun (to me). The only pro is that it ensures all agents are given the same exact computation taps with no room for noise but this really does not give sufficient benefits to warrant the problems. Perhaps history is what keeps Battlecode clinging on to bytecode counting.\nAnother issue is the visualizer, which is poorly optimized, slow, and eats up your ram. Since it\u0026rsquo;s so slow, there is much less feedback to competitors on how their current bot\u0026rsquo;s strategy is performing, making it difficult for competitors to tune their bots and improve them, with many competitors relying on pure intuition.\nIn the end, Battlecode is still extremely fun, but only for a select few who are willing to put the time in and willing to deal with a number of problems. On the bright side, their current president Jerry is extremely capable, and he is pushing for changes to improve the competition, engine etc.\nConclusion: Fun, super hard, and basically for the strong willed who are happy to drop everything for it (e.g. me lmao). Not worth doing if you are a bit more new to Battlecode or not okay with dealing with lower feedback and sometimes slow matchmaking.\nHalite Halite is extremely well designed and though out. Less active of a community in my opinion than Battlecode but they do have a rather large fan base after demonstratably being the most popular AI programming challenge of its kind (not including screeps) in recent years. The first 3 iterations ticked off a lot of boxes. Great feedback, low barrier to entry, intutive and intriguing game designs (with lots of interesting emergent behaviors), highly accessible and inclusive and the list goes on. This would be an exemplary example in DOET if DOET ever covered programming competitions.\nHalite supports just about any programming language, has a 1-2 page set of rules compared to Battlecode\u0026rsquo;s average of 10+ pages, and has a generally fast engine and visualizer that is also often well designed. You wouldn\u0026rsquo;t believe that this was mostly built by a highschool student interning at Two Sigma (who also goes to MIT, helped run Battlecode one year then left because Battlecode refused to change at the time). Moreover, the Halite competition has the most open source contributors I\u0026rsquo;ve ever seen compared to the other competitions in this blog post. In fact, a lot of the starter kits for other languages were built by the community, not Two Sigma.\nUnfortunately, Halite is no longer built by the same people at Two Sigma but maintained by Kaggle, who are trying to launch a new style of competition they like to call simulations (but we call them AI programming challenges). Kaggle had a severe number of limitations the first year and had to rush build their simulations competition platform to run the latest Halite iteration (Halite 4). As a result, a lot of problems surfaced.\nHalite 4 ran very few matches per day relative to what Two Sigma was doing in the past. From what I remember, there were typically \u0026lt; 15 matches played per day per agent, which sounds ridiculous because in previous Halite iterations, there were something like \u0026gt; 50 matches per day, and even more if you just submitted a new agent. The lack of matches and thus feedback made it difficult to evaluate your agent against other competitors\u0026rsquo; agents.\nAnother issue is that Halite 4 is effectively python only, likely in part due to the rush order Kaggle had to fulfill. Other languages might work, but aren\u0026rsquo;t supported and aren\u0026rsquo;t easy to use. If you do a bit of data analysis, you will find that the higher ranked the competitor was, the less likely they used python. So instantly, Halite 4 lost a part of the old community, and an even more significant part of the most competitive competitors since they couldn\u0026rsquo;t reasonably compete anymore. This is also reflected in the Github repository that ran Halite 4, there are much fewer open source contributors and that repo is the home for 5+ other competitions on the Kaggle platform. There\u0026rsquo;s definitely a future for AI programming competitions on Kaggle because they have the right community, but more work needs to be done (which the Lux AI Challenge is helping address!).\nThe best thing Kaggle did get right with Halite 4 is that they made it extremely machine learnable, which plays to their audience much more, with many more RL, ML solutions being submitted and many new insights\nConclusion: Probably one of the best, if not the best competition back then. Could resurface as a great competition again if Kaggle could keep a lot of the old features Halite had in terms of e.g. matchmaking, more language support, and perhaps open-source friendliness and community building.\nTerminal Terminal has a great game design, (it\u0026rsquo;s like space themed tower defence auto-chess), good visualizer, generally good development tooling. What\u0026rsquo;s interesting is that despite the simplicity, strategies can easily change by just changing some parameters of the game, making it fairly reusable which in one part is less engineering work for Correlation One (the company that runs it, almost exclusively for Citadel).\nHowever, by only changing parameters and the design itself, the game becomes very dull over time. In fact, they\u0026rsquo;ve been running this same design for 7/8 years now and you frequently can see that people can submit old bots from the previous season with minor tweaks and get generally good performance on the next season which has some obvious problems. Old competitors tend to get bored as there is much analysis to do given that most of the time the units in the game are the same, rules are generally the same, it becomes more busy work and this is reflected in the general lower amount of hype online for this competition. They do offer some of the largest prize pools though, which in my opinion just compensates for the lack of change. Halite had no prizes and still had way more competitors and much more competitive play at the very top of the rankings.\nAnother huge issue is that the goals of the Terminal competition are really just to recruit engineers and data scientists for Citadel and other sponsoring companies. The goals are not aligned with the interests of competitors. Terminal\u0026rsquo;s intentions lead to things such as screening competitors for certain competitions before they can participate, corporate overhead from Citadel (which Halite also has), and honestly a lack of effort to even just keep Terminal active and fresh like the exciting competition it once was. Halite also suffered from this in that Two Sigma decided to no longer support Halite because it had less value to them, despite having incredible value to competitors of which Kaggle recognized. Battlecode is one of the few competitions who are not hassled by corporate demands and interests, and is built for the enjoyment of the competitors.\nConclusion: Once a great competition but now outdated. Terminal is interesting the first or second time but then really not worth your time (unless you like money and they decide to increase the prize pool because they are backed by Citadel after all).\nCodinGame This is an interesting one. CodinGame is a company that has a lot of success with a specific style of AI competitions. They have a community of 2 million something members and AI programming challenges with 100,000+ competitors with their seasonal competitions bringing in 8,000+ competitors easily. It seems to be overwhelmingly popular in the French and European circles of engineers and their Discord has upwards to 20k+ members.\nThey\u0026rsquo;ve really done well to \u0026ldquo;democratize\u0026rdquo; AI challenges by making it relatively simple for competitors to build their own AI challenges, with a voting system in place to then determine which competitions are published and launched. They\u0026rsquo;ve capitalized on the incredible power of AI challenges to help identify genuine talent and outside the box thinkers and I really hope CodinGame keeps this up for as long as possible.\nOne downside is that their competitions visually aren\u0026rsquo;t that appealing or in line with modern \u0026ldquo;design\u0026rdquo; but that\u0026rsquo;s mostly my subjective view of them. The other downside is that most of their competitions tend to be too simple, with less room for emergent like strategies, and/or interesting designs that could encourage interesting play from RL and ML. It seems that oftentimes their competitions boil down to a few simple algorithms and boil their platform down as more of an algorithms education and tuning platform.\nConclusion: A great move forward for AI challenges with a ton of potential and I look forward to seeing them grow\nScreeps This is quite special in the sense that it probably has the same style as any other AI programming challenge, but it\u0026rsquo;s actually a game on Steam and by far the most popular one. The interesting part is that Screeps is actually an MMO which is not a easy thing to engineer for. UIUC\u0026rsquo;s most recent MechMania AI programming competition attempted to run an MMO AI competition and it failed completely. About 20 competitors, nothing worked, visualizer was broken, a lot of \u0026ldquo;overengineering,\u0026rdquo; and unfortunately not worth more than two sentences to talk about.\nLooking at the reviews on Steam and feedback from some of their competitors, Screeps is truly unique and extremely addicting and I wish I had the time to compete in it. It has some awesome developer tools that really define what it means to have \u0026ldquo;smooth competition experiences\u0026rdquo;, although it is primarily Javascript only (with probably good reason as something so massive may want to have more equity amongst competitor compute speeds). It has incredible graphics and developer support (although it is a paid game), and the now more recently are preparing to launch Screeps Arena which is much more like Halite, Battlecode etc. and looks crazy fun.\nConclusion: Very very well developed game and good game design and awesome tooling from what I hear. Unfortunately, it\u0026rsquo;s Javascript only and part of it is behind a paywall but there seems to be movement to help support more languages for Screeps.\nLux AI Challenge I will write a more in-depth post about the Lux AI Challenge at a future date, perhaps after Season 1 finishes. This future post will go more in depth of it\u0026rsquo;s history, and how it came about, and perhaps more on my \u0026ldquo;origin\u0026rdquo; story that led up to the Lux AI Challenge, in addition to potential future directions I think my team can help take the organization in.\nThis section will give a quick overview of my mostly \u0026ldquo;objective\u0026rdquo; view of the Lux AI Challenge.\nThe Lux AI Challenge is most similar to Halite (in addition to also being hosted on Kaggle), but has a complexity level in between Halite and Battlecode. It follows the same \u0026ldquo;hivemind\u0026rdquo; paradigm where you control many units and have them try to achieve a particular goal in a multivariable resource optimization problem in a 1v1 scenario. Differently from Halite 4 which was effectively python only, Lux AI now adds support for C++, Java, and Javascript/Typescript, with other compiled languages being easy to add.\nInterestingly, it is one of the first competitions apart from Halite (and somewhat recently Battlecode) to really try to build gender-neutral designs. Details like these tend to go unnoticed to most competitors and observers but a step forward towards building a competition for everyone via gender-neutral designs is always better than no steps at all. In particular, Lux AI Challenge has even gotten itself referred to as being \u0026ldquo;cute\u0026rdquo; on twitter (in japanese), which is definitely an adjective you would almost never associate with a programming competition. Did I forget to mention, Lux AI also has incredible graphics designed by Isa Pan, our head of design (or chief design officer, we don\u0026rsquo;t have labeled positions at the moment). If I were to rank graphics, I would put Lux AI first, then Screeps, then Halite.\nAnother point is that the Lux AI Challenge heavily builds on 3 key goals, novelty, inclusivity, and accessibility. Things like gender neutrality help target inclusivity. Our plan is to also remake the competition each year using our long history of competing and building competitions, targeting novelty. Then small details such as color blind palettes go a long away to helping improve accessibility. It\u0026rsquo;s not all perfect though. The visualizer (I\u0026rsquo;m at fault here) is not very well optimized in that while most computers can run it smoothly, older laptops tend to struggle a bit and it\u0026rsquo;ll eat away a lot of RAM, creating a bit of an accessibility problem here if not dealt with.\nAnother great thing about the Lux AI Challenge is that like Battlecode, the intentions are solely focused on giving the competitors a great competition. The Lux AI Challenge does not intend to be for-profit (and eventually will register as a non-profit when feasible), and as a result, this lets us really explore a whole wider range of options in terms of how to improve competitor experience, without having to close down like Halite went through because it no longer became \u0026ldquo;worth it\u0026rdquo; to Two Sigma.\nThe non-profit mindset gives us a ton of opportunities to be different, from cultivating a open community like Battlecode to funding outreach programs to teach AI and Computer Science to underrepresented demographics, schools without standard curriculums in CS, and more.\nConclusion: Up and coming competition with goals that could shape it into being a long lasting, constantly exciting AI challenge that is truly open to all. Currently undergoing growing pains that may make Season 1 not as great as future Seasons.\n🌊\n","permalink":"https://blog.stoneztao.com/posts/ai-challenge-survey/","summary":"A Survey of AI Programming Challenges In 2018, I got my first real taste of an AI programming challenge. It was MIT\u0026rsquo;s infamously difficult Battlecode. I competed in it with a few friends on a complete whim. I had no knowledge of Java or any algorithms/data structures and as expected we basically sucked really hard. Flopped every tournament. You would not expect someone to suddenly make finals the year after, or consecutively for 3 years in a row, to then go on to be extremely interested in AI.","title":"A Survey of AI Programming Challenges"},{"content":"How to Survive a Graduate Course as an Undergrad At UCSD, graduate courses in computer science can be split generally into two categories. Courses that teach advanced topics for graduate students that extend the advanced courses designed for undergraduates, or courses that are fast-tracked versions of undergrad courses. Then there are research-centric courses that usually target a very specific domain and are run by a professor and/or their lab at UCSD. Both types are difficult, but the research-centric ones can vary wildly in difficulty.\nThese research-centric ones include the CSE 291\u0026rsquo;s at UCSD.\nI took CSE 291-I at UCSD in the 2021 winter quarter (UCSD is a 3 quarter system). It\u0026rsquo;s definitely not a course you can easily just walk through, given the fact that the content covers research published as recently as a few months ago, with assignments relying on research as early as 2 years ago.\nIn this post, I\u0026rsquo;ll talk about what I learned from this course, why I recommend graduate courses, and how one could succeed in such a demanding course. To cap it off, for my fellow UCSD students, I detail about how to enroll in graduate courses given the fact that graduate students all get priority and, sometimes it\u0026rsquo;s not clear as to what courses might be a good fit.\nCSE 291-I is a course at the intersection of geometry and machine learning. I learned a ton from differential geometry, the mathematics of rotation, SO(3), relevant optimizations algorithms, to classical and deep learning approaches to tasks such as 3D object segmentation, detection, and pose estimation. The course also introduced me to a lot of terminology and concepts necessary for understanding and working in the 3D computer vision field and brought in tons of top researchers in the field to give talks about their work such as human pose estimation by Angjoo Kanazawa (Berkeley, Google Research) and 3D detection by Charles Qi (Stanford, Waymo).\nThis course at its core is math and programming heavy, with the homework being effectively solving math problems and programming models to solve a particular task like segmentation or pose estimation. What made it really fun was that there was a live benchmarking site where we submit our model\u0026rsquo;s predictions to be ranked against everyone else in the course. At the end, after the final project, I effectively got to build a full 3D object pose estimation pipeline that takes as input just RGB-D (RGB and depth) data and various other metadata to predict poses of objects.\nObviously, just about every single PhD student from Hao Su\u0026rsquo;s lab ranked top. Although I would be curious if they could predict object segmentations for some funny samples I found when fine-tuning a Faster RCNN model:\nIf you\u0026rsquo;re interested, a full syllabus + most of the course slides can be found on the course website: https://haosulab.github.io/ml-meets-geometry/WI21/index.html\nThere are a myriad of reasons aside from a graduate course looks great on your resume / grad school application.\nFor one, the content taught is often closer to what state of the art methods rely on. The presentation by Charles Qi included work that was published just last year in CVPR 2020! I effectively learned what the state-of-the-art approaches to different tasks are at the moment and if I wanted to, could implement them to varying degrees of success.\nApart from learning about the literal frontier of computer science, these graduate courses give you a much more in-depth exploration and study of various topics. Sometimes the content is only recently researched, meaning there is a ton of opportunity for discussion on completely novel ideas!\nMoreover, research-centric courses usually have a smaller class size, which often invites a lot of insightful discussion and more 1 on 1 interactions with the other students and the professors. Most of the other students and the professor will have more experience than you, so to learn from them is a great opportunity that you won\u0026rsquo;t often get at an undergraduate course.\nTaking a graduate course has its many benefits, but at the end of the day it\u0026rsquo;s not worthwhile if you can\u0026rsquo;t do well in the course and/or ingest the content at a reasonable pace. These courses can be demanding. So here\u0026rsquo;s a few general tips\nStart early. You are highly likely to be behind in terms of necessary content. Unless you are an absolute genius, you have some catch up to do. For example, for CSE 291-I, our first homework was a refresher homework, meant to test our knowledge on basic requirements from probability to deep learning. Starting early will give you the appropriate time to catch up on some parts of the material and do well on homework and exams. Planning to take a course ahead of time will also give you time to refresh yourself on relevant material\nAlways ask for help! Don\u0026rsquo;t be afraid to ask a stupid question, for all we know, other students are thinking the same thing. Luckily for my course, the professor encourages students to ask as many questions as possible and this is often the same for other professors. Questions not only get you recognized but help initiate an open discussion that is often rewarding. You don\u0026rsquo;t always get a free chance to openly talk with the professor and disucss ideas. Moreover, the professor\u0026rsquo;s job is to help you succeed in the course, and if you don\u0026rsquo;t communicate, you make it just that much more difficult for the professor, they are there to help!\nDevelop a solid mathematical background. This might be one of the biggest caveats of higher level computer science courses. There is going to be math, and it is going to be hard if you don\u0026rsquo;t learn the appropriate mathematics. Mathematics powers a ton of the heavy machinery used in computer science and a single lecture can easily get you lost in unknown symbols if you don\u0026rsquo;t have a decent grasp of the math. Depending on domain, the graduate course will require different types of mathematics that you should make sure you have a decent grasp on. Don\u0026rsquo;t be afraid to re-read your old linear algebra notes or refresh your knowledge on vector calculus, you will need it (subject to course domain of course).\nFor students at UCSD, I highly recommend taking MATH 109 (Mathematical Reasoning) or MATH 31AH-CH (honors math) before diving into any more upper division math courses like statistics, numerical optimization, etc. MATH 109 or MATH 31AH-CH will give you a good problem solving framework and learn how to prove in math, which will greatly help you understand a long sequence of equations in any lecture or paper.\nAnd some tips for courses with a ton of programming around deep-learning. This assumes you have decent familarity with python and a deep-learning framework like PyTorch or Tensorflow or whichever language and framework pair for the task at hand.\nBuild out a flexible data pipeline. My biggest mistake was trying to fiddle around with a small sample of the data and get some algorithms and models to work instead of building a flexible data pipeline to then test on. As a result, a lot of my code was very specific to the small sample of data and I spent a lot of time just reengineering code and reading my testing code to then build the datasets and pipeline for the course\u0026rsquo;s homework.\nBy building a proper pipeline, not only is it easy to understand and use your code, but it\u0026rsquo;ll probably speed up your training and testing process. Big recommendation: use the Data module from PyTorch or the Data module from Tensorflow if you use TF. Moreover, if you keep the data pipeline flexible, e.g. letting you vary the number of samples included in the dataset, you can then start doing the exploration stage of models much more easily and a simple change of a dataset parameter will instantly change your exploration into \u0026ldquo;production-ready\u0026rdquo; code (production ready as in you can use it now to finish the homework completely).\nStart small and naive, then increase complexity. A simple, naive model helps you find bugs early on e.g. forgetting to scale/normalize data, faulty training scripts etc. Once you know everything works, then you can incrementally start adding components to your model or implement more complex architectures.\nDevelop visualization functions. Visual feedback is one of the best ways to understand what\u0026rsquo;s happening with a model, especially in computer vision. Without the feedback, it\u0026rsquo;s difficult to tell if your model is working as intended, and you will probably want to have some simple scripts to visually interpret model inputs and outputs, its architecture, etc.\nUsing Jupyter Notebook. Software such as Jupyter Notebook is great for exploratory programming when you want to test our new code and debug it, as well as explore potential options for a new model, algorithm etc. The fact that Jupyter Notebook lets you run parts of your code separately enables a ton of flexibility in development. Moreover, oftentimes there might be some data-loading involved that could take a while and Jupyter Notebook will let you load that into the RAM and keep it available while you explore instead of having to load it up again every time to test a new bit of code.\nLast thing, be ok to jump ship and drop the course. Not all courses selected will turn out great for you and that\u0026rsquo;s fine! Come back next quarter, or even next year. I promise you you won\u0026rsquo;t be behind, the fact you might consider a graduate course as a undergraduate means you are way ahead of other students already and are not falling behind in terms of coursework.\nThere are two parts to enrolling in a graduate course.\nFigure out if the graduate course is suited for you and you can handle it.\nTry to enroll in the class (can be a bit tricky)\ntldr; For enrolling in graduate courses, always ask the professor about the course and ask them to help you enroll. It helps if you know the professor, have taken relevant courses, and can demonstrate a strong interest. Do all of this as early as possible.\nFiguring out if the course is right for you and you can handle it. A lot of these graduate courses might not have enforced prerequisites, which means it is completely up to you to determine if you can handle the course load (even if there are some prereqs, they may not be accurate). Often times it\u0026rsquo;s difficult to determine because a lot of the course descriptions put up online are limited, and any information regarding prerequisites is also limited.\nTo address this, you should definitely email the professor running the course, ask them if given your background (list what you think might be relevant), if this course would be a good fit. This is also a great chance to ask any questions and to get to know the professor (which will help later when enrolling).\nIf you are working at a lab that does similar work (or helps run the course you want to enroll in), I then also recommend asking the PI (principal investigator) of the lab for help on finding the right course and about whether you should join that course.\nEnrolling Don\u0026rsquo;t panic if the webreg system doesn\u0026rsquo;t let you enroll / waitlist because you don\u0026rsquo;t have authorization, and don\u0026rsquo;t panic if your request to enroll / waitlist is not reviewed for a while.\nFirst, realize that most of these graduate courses require graduate standing, preventing you from enrolling directly, so you will need to file a pre-authorization request. Even then, for the CSE department at least (and I suspect other depts. as well), they will not grant your request or consider it until all graduate students have had a chance to enroll / waitlist.\nNow supposing all grad students are finished selecting their courses, if there is still space left in the course, likely the department will then approve your request to join the course.\nNow what might be more likely, there is a waitlist or there are just no spaces. Unfortunately, you will probably not get your authorization approved or even reviewed until all graduate students on the waitlist are removed. So considering this potential outcome, you should always reach out to the course professor weeks in advance and ask about whether it\u0026rsquo;s possible for you to join the course and if not, ask if you can audit the course and join the lectures etc. Remember, in the end, a primary goal of taking graduate courses is to learn! Auditing is one way of doing it, albeit your homework and exams will not be graded.\nIt helps to know the professor beforehand or any professor who can put a good word in for you. In my case, my professor for the grad course is also the PI of the lab I\u0026rsquo;m in, so that was not difficult to ask for enrollment authorization. Reaching out to the professor beforehand is a great way to demonstrate interest and most professors are more than happy to find potential new students for their courses and their labs. Otherwise, the advice above is some advice that I collected from talking to other students who enrolled in graduate courses. Anyway, blog post no.4 done,\n🌊\n","permalink":"https://blog.stoneztao.com/posts/grad-courses/","summary":"How to Survive a Graduate Course as an Undergrad At UCSD, graduate courses in computer science can be split generally into two categories. Courses that teach advanced topics for graduate students that extend the advanced courses designed for undergraduates, or courses that are fast-tracked versions of undergrad courses. Then there are research-centric courses that usually target a very specific domain and are run by a professor and/or their lab at UCSD.","title":"How to Survive a Graduate Course as an Undergrad"},{"content":"Battlecode 2021 Postmortem This is my 4th year competing in MIT Battlecode. I previously competed as Bowl of Chowder (5th) in 2020, and as Codelympians (9th) in 2019 and was Codelympians in 2018 but did not make finals the first year.\nThis year I once again soloed my way to finals, achieving 9th overall, and to my surprise, won the \u0026ldquo;Adaptive Strategy\u0026rdquo; award for spearheading the development of a strategy known as \u0026ldquo;muck flanking.\u0026rdquo; My team name was California Roll (however it\u0026rsquo;s listed as Chop Suey online)\nApparently a significant number of people read my postmortem from last year. Traffic to that post jumped by ~1000% for a few days and was quite high over the course of the competition. As a result, this incentivized me to write a better postmortem that isn\u0026rsquo;t all about a single competition that most people won\u0026rsquo;t understand without having competed in it. Instead, I decided to have a gentler introduction that isn\u0026rsquo;t a wall of text, and focus more on general points not specific to Battlecode 2021, but on Battlecode and AI programming competitions in general. I still include the traditional \u0026ldquo;timeline\u0026rdquo; format of Battlecode postmortems in a later section. I also now include my evaluation of the year\u0026rsquo;s design, it\u0026rsquo;s features, what makes it good / interesting / fun, and what wasn\u0026rsquo;t so great. If you want to read my unreadable code, it\u0026rsquo;s here: https://github.com/StoneT2000/Battlecode2021/\nA Gentle Introduction So what is Battlecode? It\u0026rsquo;s this thing. Longer answer: it\u0026rsquo;s a student run organization at MIT dedicated to hosting an annual AI programming competition that pits your strategies and code against other competitors for a sizable prize pool. They welcome competitors of all ages, although the main tournament is for full-time students / students in transitionary periods only.\nBut what exactly is AI programming? No, it is not necessarily advanced, state of the art, reinforcement learning algorithms using PPO. It can be, but in the context of Battlecode it\u0026rsquo;s usually near impossible to use advanced AI algorithms due to a whole host of reasons. So now what? We rely on good old fashioned reliable: conditional branching. Every single bot submitted to Battlecode (that performs well) is effectively a giant, carefuly curated, grown, and pruned, decision tree (with some pathing and optimization algorithms here and there).\nYour programmed agent received state information about the game it is playing from the engine, and then it sends back it\u0026rsquo;s actions. Rinse and repeat. This keeps going on until one team objectively does better after a time limit, either by playing the game correctly and scoring high on some metric, or in the case of Battlecode, absolutely annhilating the other agent on the game field.\nThis kind of AI programming requires a different kind of thinking and analysis. The creative kind, as well as the copying kind (more on that later), perhaps well combined into creative copying. This different kind of thinking is what allows top competitors to create the best bots, in addition to some decent programming skills but you usually never go beyond a Dijkstra\u0026rsquo;s difficulty algorithm.\nIf you want to get involved and compete, I highly recommend joining the Battlecode community and discord: https://discord.gg/zYzCjEvuuJ. Battlecode has been historically deeply rooted in traditions (like finalists playing the Terraforming Mars board game at the finals) and a strong community. I think even half of the dev team, including their current president Jerry, are Battlecode alumni, with Jerry having most recently competed back in 2019. Shout out to all the legends who have been around for years. It\u0026rsquo;ll be sad to see that XSquare (who is on his 7th? year of Battlecode) is finally graduating from graduate school and no longer eligible to compete in the main tournament anymore. Regardless, it is a community you don\u0026rsquo;t want to miss out on. It was thanks to Battlecode that I got into computer science, cogntive science and AI! I for sure will not make 2021 my last year of Battlecode.\nWhat Got Me to Finals First I\u0026rsquo;ll define a few common keywords / AI competition jargon that often gets thrown around\nEconomy: Usually in a competition, especially in Battlecode, there is some sort of resource that enables your bot to do something. A bot\u0026rsquo;s economy is then based on how well they generate this resource.\nSpecs / Design: I like calling it the design but its more commonly referred to as the specs. This is the document / information that defines how the competition works, how one or more agents compete to get rankings / scores.\nMacro / Micro: Macro refers to strategy that controls overall behavior of a bot. Micro refers to strategy that controls specific, local, behavior of a bot at the smallest scale (e.g. individual unit behavior).\nRNG: This stands for random number generator, but it describes events that just occur by chance or objects that can randomly cause / change behavior by chance. This is also sometimes used like a verb to say something was impacted by random chance.\nThis year a few major factors helped me make it to the finals of Battlecode.\nTotal disregard for homework and finishing them the day they are due (don\u0026rsquo;t do this please) Copying early-game build queues \u0026ldquo;Spearheading\u0026rdquo; the development of a strategy known as \u0026ldquo;muck flanking\u0026rdquo; and being one of the first to use it Being fairly active on discord (or at least reading strategies and ideas that were floating around). The above points are quite general and usually apply to every year of Battlecode, with point 3 being specific to this year.\nLast year I may have bombed a midterm while doing Battlecode. This year I had to clutch two homework assignments and submitted one of them during the 5 minute submission grace period at 12:03 AM, solving the last problem at around 12:01 AM after submitting the rest at 11:55 PM the previous day. I highly do not recommend disregarding homework. To be frank, I was lucky that the homework assignments weren\u0026rsquo;t too bad and were on topics I knew fairly well, but I might not be so lucky next year. This is typically a result of 1. UCSD starting on the same day Battlecode starts and 2. soloing each time.\nThe most clutch moment of my academic career\nRegardless, my disregard gave me more time to tune my bot, add some nice features and the biggest constraint in Battlecode is usually time. Competitors are given about 3 weeks to code a bot ready for qualifiers to then qualify for finals, with then about 2 more days to further develop the bot for the finals tournament. Add on the usual spec changes that occur during the middle, time is really hard to come by. Many teams including mine end up having long todo lists that can\u0026rsquo;t get finished because there is simply not enough time to code our ideal bot.\nSomething that also helped me a great deal and bounce back after the nerf to a crucial feature that was winning me games was copying some other top bot\u0026rsquo;s build queues. Build queues are the order in which your controlled buildings build units to interact with the game and win. Apparently I had a pretty bad initial build queue that put me at a significant resource disadvantage a lot. After copying other team\u0026rsquo;s queues, I instantly shot back up.\nMy highest ranking was a 2nd place on the ranked leaderboard after I started to abuse my muck flank strategy more explicitly instead of implicitly (unfortunately after nerf the strategy was less overpowered). It was originally something my bot did on accident, but after I saw the potential I made it more explicitly coded into the bot. But regardless of what exact strategy this was, the key point is that careful analysis of match replays is crucial to doing well. Without analyzing past matches against myself or other bots I wouldn\u0026rsquo;t have been able to abuse this strategy more, or copy strategies from other players.\nLastly, being active on discord as usual helps quite a bit for me. It\u0026rsquo;s funny with its memes and stuff but is also another medium to glean strategies, copy strategies, and discuss strategies with other competitors. There\u0026rsquo;s always going to be people on discord sharing ideas that have proven quite useful. For example, I didn\u0026rsquo;t notice you could actually encode a location on a 64x64 map in 14 bits when all the map coordinates are offset by values on the order of 10^4. It was only until I caught onto some discussion about it until I realized my mistake, and thus improving my bot efficiency 2 fold in comms.\nLessons Learned Do not assume early, copy more, read specs carefully, flesh out features on specs before code.\nBasically, a combination of the above 4 points led to a lot of time wasted on my bot this year, as well as some poorly written code and strategy. This is evidenced by how my final bot\u0026rsquo;s files has a lot of unused code from old scouting code to unused communication signals.\nIn the first week, I decided that pathfinding was not going to be important since there were no real walls on the game map, just passability values representing how long it takes to get across that map tile. Thus instead, I decided this year I would focus more on good communication code and optimization and assumed that pathfinding wouldn\u0026rsquo;t come back to bite me. This was most likely a mistake. The exact reasons are explained in the timeline section, but from a high-level, very greedy pathing was a lot worse than I anticipated than optimized pathing based on something like Dijkstra\u0026rsquo;s algorithm. Making such a big decision early on setup my bot for a lot of issues. With less focus on pathing, I had pathing problems for a week and a half that I didn\u0026rsquo;t notice, as well as issues with being very slow to gain map control as my units take much longer to get to the opponent, as well as poor attacks as my units also take forever to launch an offensive.\nSurprisingly, I didn\u0026rsquo;t end up copying opponent teams as much as I usually do. The time I did (copying build queue) I instantly did better, so somehow this reward signal did not resonate deeply this year. On the bright side, this is the first year I\u0026rsquo;ve heard of other teams copying me as opposed to the other way of around. Supposedly one team copied my build queue (which was adapted from team confused and team Malott Fat Cats) and multiple teams copied my slanderer latticing strategy (although I think latticing was quite an obvious strategy that most people figured out themselves)\nAnother issue was a poor / messy understanding of the specs this year. I\u0026rsquo;d like to argue from a design principle angle, this isn\u0026rsquo;t much my fault, Battlecode should just work on having more concise and unambiguous specs. Regardless, I still felt that I misread quite a lot early onto the game, making me throw away some of my initial code. Not understanding this year\u0026rsquo;s specs that well also caused some erroneous / poorly thought out code to be left in my bot.\nEven towards finals, I was considering some new strategies that actually wouldn\u0026rsquo;t work because of limitations I didn\u0026rsquo;t read carefully about. I dived straight into the code and implmentation of some strategies without having fleshed out its feasibility on the specs first, assuming that my conceptual model of the specs were accurate. As a result, more code was written that got thrown away / left in the bot that doesn\u0026rsquo;t get used.\nThe Battlecode 2021 Timeline This section covers a intro on the 2021 iteration of Battlecode specs and how Battlecode works, how the meta / strategy developed over time in relation to the tournaments and my own bot. It dives into some of the unique strategies used as well as looking into how teams reacted to various spec changes and more.\nIntro to Battlecode 2021 This year, Battlecode 2021 was based around 4 units, Politicians, Muckrakers, Slanderers, and Enlightment Centers. The objective was to either have the most votes by the end of the 1500 round limit or to eliminate all opposition units from the field.\n{{ }}\nEach of these units had different properties and abilities that helped shaped the virtual political landscape as either party wrests for control of the map. All units have a certain circular vision radius, determining what local information is visibly available to the unit. Morerover, every unit can perform some acton each turn provided their cooldown is below 1. Different units increment cooldown more than others when performing actions.\nEvery single unit runs its own instance of your code, and cannot share variables with other units nor even see them unless in their vision radius.\nIn particular, mobile units have influence and conviction. Their conviction value is dependent on their initial influence, and can change over time depending on what happens.\nAnd as usual, the game is situated on a 2D square grid map where units can move in 8 directions (North, Northeast, East etc.) and all units run in order of a turn queue. However, unlike previous years, there are no walls that can block movement. There is a concept of passability for each map tile, which determines how much more a units cooldown increments whenever they perform an action on that map cell. So low passability tiles on a map slows down mobile units because movement is an action and will increase cooldown a lot more than other higher passability tiles. Immobile units are also affected by passability. In future pictures, low passability is denoted by dark tiles, high passability is denoted by green tiles.\nNow I will explain the units from a high level.\nEnlightment centers (EC) are the only immobile units. They hold influence that can be spent to bid each turn for a vote or build mobile units with starting influence equal to the influence spent. The way voting works is that every single enlightment center on the map, your team or the opposition team\u0026rsquo;s, must bid to gain the vote that turn. The winning bidder gains the vote, whilst the losing bidder still loses half of their original bid (there some more specifics but this is the gist). On the map, both teams start with at least 1 EC, and there can also be neutral ECs that can be taken through using politicans (explained later).\nPoliticians (Polis) have the ability to empower nearby units in a certain radius that is capped. This will cause the politician to disappear from the map and distribute a function of its current conviction to all units in the radius evenly. All friendly units will gain conviction and all enemy units and neutral units will lose conviction.\nMuckrakers (Mucks) have the largest vision radius and also have the ability to expose slanderer units to increment what is known as the muck buff. This muck buff factors into the function used by the engine to determine how much conviction is distributed to nearby units when a friendly politician uses empower. Interestingly, muckrakers are the only unit who\u0026rsquo;s starting conviction is not equal t the starting influence, but is capped at the ceiling of 0.7 * influence. While they have largest vision radius, they have a smaller, limiting action radius.\nSlanderers (Slands) have two passive abilities. Their embezzle ability lets the slanderer generate influence for the EC it was built from each turn for the first 50 turns, it is a function of the influence in the slanderrer. Their camouflage ability makes slanderers look like ordinary politicians to all units except muckrakers. Moreover, this passability ability has it such that after 300 turns since being built, the slanderer converts into a politicial of equal influence and conviction to itself currently. Slanderers also have the lowest vision radius.\nBattlecode 2021 Competition Format There is almost always a ranked scrimmage leaderboard which ranks the teams with submitted bots by ELO. A team can also request unranked scrimmages against other teams for testing purposes (or memeing around as some teams did). This is used by teams to estimate their bot\u0026rsquo;s relative ability and help teams develop new strategies to win.\nThere are always a few tournaments that lead up to the qualifiers and then the finals tournament.\nThis year teh devs (the name for the Battlecode devs) decided to switch out the seeding tournament for a second sprint tournament. So there are now 2 sprint tournaments, one happening after the 1st week and the other after the 2nd week of Battlecode. Previously, the seeding tournament was used to seed teams for the qualifiers tournament.\nThe qualifiers tournament determines the top 16 teams that get to compete in the finals tournament and get a share for the grand prize pool. Usually, there is an international qualifiers tournament that determines the top 4 international teams that go to finals, and a US qualifiers tournament that determines the top 12 US teams that go to finals.\nThe finals tournament is the very last tournament that concludes Battlecode and is typically run as a double elimination tournament, with each match up being a best of 5 game.\nThe change from seeding to another sprint tournament is quite a good change in my opinion because previously the seeding tournament, qualifiers tournament, and finals are only for competitors that are full-time students / students in a transitionary period. Moreover, all tournaments are a knockout bracket style competition, so the previous seeding tournament will sometimes result in inaccurate seedings for qualifiers, making it sometimes unfair. Instead, using the scrimmage leaderboard to seed for qualifiers is much more accurate as it uses the ELO ranking system and runs hundreds of ranked matches between competitors to determine their relative ranks.\nLastly, there are also the high school and newbie tournaments which are for high school students and firstime MIT students competing in Battlecode respectively.\nTLDR; This year, there were quite a few spec changes, a lot of erratic behavior and RNG. So tldr; this is what happened\nThe tldr; of Battlecode 2021 summed up in memes and my ranking graph\nSprint 1 - First 7 days - Muck Spam I had trouble understanding the specs a lot, so safe to say, I did very bad in sprint 1, getting knocked out due to a bidding issue that. But prior to sprint 1, some common observations surfaced. Cheap, 1 influence mucks were very efficient and can waste the opposition\u0026rsquo;s influence as due to the function that determines a polis\u0026rsquo;s conviction distribution when it empowers, it requires a minimum of 12 influence to destroy a 1 influence muck. Another thing that was observed was that as units can be built with variable influence from 1 to some max value, a more important resource is EC turns, not influence. EC turns referred to how many turns you got to use to build a unit that turn. Thus, having more ECs controlled meant you could dominate the map with tons of units that would force the opponent into a corner and win you the game.\nMy team in Red against team Blue Dragon, both emplyoing muck spam. However, Blue Dragon initially builds polis and slands that my muck spam instantly get rid of, resulting in my unit dominance\nAs a result of these observations, many initial strategies were surrounding muck spam, and these worked quite well initially. The only downside of muck spam was that while a poli wastes a lot of influence to destroy 1 muck, due to empower mechanics it was quite good to focus on destroying 2 mucks or more at a time, which gives your team a EC turn advantage and thus a unit advantage.\nHowever, since cheap mucks were quite ubiquitous, one would think building slands was not a good idea since it would be hard to defend against a horde of cheap mucks. Moreover, if the opponent was smart, they could space out their mucks so they cannot get two bird one stoned by a single poli. However, not building slands turns out to be not optimal, and the best muck spam strategies ended up needing slands to help capture neutral and enemy ECs to gain more EC turns as EC turns are a crucial resource. This meta developed later into around sprint 2 and qualifiers.\nLastly, a common thing echoed by competitors was that pathfinding this year wasn\u0026rsquo;t that important. This is to some extent true, and for the first few weeks having mostly greedy path finding worked fine. But once my bot started competing against the stronger teams, towards the end of Battlecode teams started to have better pathfinding which gave them a stronger edge.\nSo muck spam, optimal poli empowerment, and perhaps some light eco seemed to be about where the meta was at the moment. Eventually, tscmoo of team Super Cow Powers takes the sprint 1 tournament win after defeating team babyducks in the final match.\nSprint 2 - 7th to 14th day - Broken Exponentials, Proper Economies, Buff Mucks, Muck Flanks Broken Exponentials After sprint 1, people started to realize that one could self empower to gain infinite influence. Clearly, this was a very broken strategy and not intended by teh devs. The idea was that you would use mucks to expose slanderers, giving oneself a big muck buff. The formula for calculating the conviction distribution of poli empower is scaled linearly with the muck buff. As a result, a EC could spend all its influence on a poli, and then poli would empower to give even more influence back to the EC thanks to the multiplicative buff.\nWhat made this strategy even more broken was that the muck buff increased at a exponential rate. The buff was equal to 1.01 to the power of the sum of influence of all slands that were exposed by your team in the last 50 turns. This meant that exposing about just 70 influence worth of slanderers gave you a 2x buff, which can easily explode to give you tons of influence. After a EC gets a ton of influence, it no longer even needs to build units, it can just bid and wait out the game, easily winning the match.\nThis resulted in a lot of erratic behavior and many teams jumping up and down purely depending on which team exposed the other team\u0026rsquo;s slands first.\nFrom what I hear, team Nikola heavily abused the muck buff to get tons of influence. Interestingly, the top ranked leaderboard team, Malott Fat Cats, never used the muck buff and still do very well (belived to be insanely good micro code). Nevertheless, my bot hopped on the band wagon and exploited the muck buff to help me shoot up the rankings and finally land in the first page of the leaderboard, the top 10.\nFortunately and unfortunately, this buff made me win games, but also lose games due to some absolutely hilarious bugs.\nHere\u0026rsquo;s one between my bot against team babyducks. So while i have barely any units left, I got an extreme muck buff and have a total influence of 74785406 from summing up all the insane influence stored in my ECs. Meanwhile babyducks is severely losing with 400x less influence than me. But then my big ECs do this:\nThey decide to build two giant politicians, one with 23,398,113 stored in it. That\u0026rsquo;s a third of all my total influence. Then about 15 turns later because I used all my EC influence on those polis, that EC gets taken. So ok, maybe my big polis will just take a new EC and at least I\u0026rsquo;ll still survive and that amount of extra influence will be transferred into the new EC and I can keep voting and ride out the last 300 rounds of the game. And great, this is actually what happened\nBut here\u0026rsquo;s the problem. That EC builds 2 slanderers using all of its 5.4 million influence. About 10 turns later, the total influence of both teams flips:\nThe above happened in one turn as babyduck\u0026rsquo;s nearby muck exposed both of my huge slanderers. Safe to say, I didn\u0026rsquo;t win that match.\nDuring the middle of this period, teh devs finally decided to lower the exponential base of the exponential base by a constant. This didn\u0026rsquo;t really do anything. Muck buff remained overpowered still.\nProper Economies This occured near the end of the sprint 1 period and early into sprint 2. People realized that muck spam isn\u0026rsquo;t good enough since you can theoretically stop mucks and also gain unit count advantage using politicians and spending influence on slanderers to back up the cost of the politicians easily.\nThe above is a game between Producing Perfection (blue) and me (red). Both of us have already realized that having some slands is better than none. However developing a economy is difficult because if one builds too many slands, you would be susceptible to being exposed by enemy mucks.\nAnother common thing that was done was building lattices of slands. This was good because it meant you could move your slands close to your EC for protection while still allowing fluid movement through the slands so your EC can still build units and units can leave and attack or protect.\nA big problem that most teams worked on tackling was muck defence. Early on babyducks employed a feature where they had polis circle around their EC constantly, which is 1. easy to code, and 2. naturally balances the amount of polis in every direction to protect the slands near their EC from all directions. I opted to go for a poli lattice, believing this sparser solution was more efficient, and created a bigger scouting network. The broader scouting network would help alert my units early on where mucks are to optimize which units should target which mucks, and which direction should my slands runaway towards. However, this suffered a bit on the balancing side as sometimes my polis will be concentrated on one side of my EC, giving the enemy mucks open access to another side and exposing a lot of my slands. This ended up being a problem that was stuck on my todo list for a while.\nInterestingly, this was also one of the few strategies I initiated was unique to my bot that people copied. Team Producing Perfection and team Hard Coders and probably some other teams used the same poli lattice for defence. However, there was quite a bit of split on this strategy as many other bots opted for babyducks idea of circling polis, which then developed into \u0026ldquo;electron\u0026rdquo; polis that would try to keep their distance away from other polis while forming a circular network around the EC.\nBuff Mucks It was well obvious that everyone prerferred to build cheap 1 influence mucks to roam the map and expose slands and scout the map. It was also observed that many many teams overfit their bots on the assumption that mucks were only going to be 1 influence. Thus, naturally, buff mucks, mucks that have a lot of influence and thus conviction, were a natural strategy for beating teams easily and getting huge muck buffs as they were not defended against and their high conviction makes them more difficult to get rid of.\nInterestingly, because of how obvious it was that buff mucks were a good idea to implement, these buff mucks did not surface amongst the top bots until very late into the sprint 2 period. Once it did, of which I believe babyducks and producing perfection were the first bots to do so, they instantly shot up in rankings. I too followed suit very soon.\nThis then grew into a new problem of buff muck defence. To defend against buff mucks before they get to your slands, you will need to build a big enough poli in time to catch the buff muck which requires a good scouting network to inform the EC early on about approaching buff mucks. Moreover, slands need early warning because it takes more time to empower out buff mucks and so slands need to run away earlier. This easily compounded into hundreds of lines of code for me and other teams as we tried to deal with buff mucks to various degrees of success.\nI decided to not worry about defending buff mucks, mostly because I wanted to focus on a new strategy, the muck flank, and also I had to clutch homework that week.\nMuck Flanks So this was a total accident. I am likely not the first bot to inadvertendly use this strategy, but I probably was the first one to give it a name and then heavily abuse it, which inclined teh devs to award me the \u0026ldquo;Adaptive Strategy\u0026rdquo; award.\nThe idea is simple. Usually most teams send cheap mucks and buff mucks directly at a enemy EC where there is likely to be many slands to expose. This is a simple and direct strategy that will work for the most part provided the enemy can\u0026rsquo;t muster enough influence to help defend against the buff mucks. But this is defendable to some extent because the slanderers can run away in the opposite direction out of the vision radius of the buff mucks, making it take a lot longer time for the buff mucks to expose the enemy slands, and giving the enemy time to raise a big enough poli to get id of the buff muck.\nEnter muck flanking. The idea is that flanking helps to send your mucks at the enemy EC from different directions instead of a single one. What this does is that it splits the focus of the enemy EC when trying to find one of your buff mucks to throw a defending buff poli at. Importantly, it also addresses the problem where enemy slands that are given early warning can run away out of sight as now with mucks coming in from different angles, there is less space for enemy slands to move out of sight and is much more likely to be seen by one of the mucks. Finally, it helps easily defeat teams that do not balance their politicians out and have gaps in their defences as flanking mucks have a higher probability of approaching the enemy EC from an unprotected angle.\nA annotated screenshot of team babyducks (red) against me (blue) with my buff mucks circled and their movement directions, as well as general attack directions from my ECs to other ECs. The flanking in this match won me the game in the end\nThis idea originally came about when I noticed in my matches I had scouting mucks that liked to traverse along the edges of the map as opposed to more optimal scouting of spaces it hasn\u0026rsquo;t seen. As a result, they tended to come and find enemy ECs from behind or the side while my ECs were sending buff mucks directly at those enemy ECs. To my initial surprise, my team was easily exposing the enemy slands. This flankk strategy was quite effective and I tried to abuse it more by forcing my ECs to send buff mucks to travel the edges of the map and attack the enemy ECs and their slands from different angles. As you could see in the tldr; picture shown earlier, this helped me peak to 2nd place on the leaderboard as I demolished enemy slands one after another and easily got infinite influence.\nThis strategy was abused and explicitly coded into my bot fairly late into the sprint 2 period and so from the rating graph you can see the flat line representing ranked scrimmages being paused for the sprint 2 tournament before my ELO started to kick off and rise very fast thanks in part to this strategy.\nHowever, this strategy could\u0026rsquo;ve have been done much better. This was on my todo list but I was considering coordinating muck flanks and attacks so that they would all converge onto a location filled with enemy slands at once, making it very difficult for enemy teams to spawn enough buff polis to deal with my mucks. In this iteration of the current spec, the moment one of my mucks get through enemy defences, it was basically game over as I could get infinite influence as a result from exposing enough slands.\nOnce again, congratulations to tscmoo of team Super Cow Powers for taking the sprint 2 tournament as well, interestingly facing babyducks again.\nNotably as well, many of the top bots were named after animals. This animal kingdom was comprised of team Super Cow Powers, Monky, Chicken, Malott Fat Cats, babyducks, and Blue Dragon.\nQualifiers - 14th to 21st day - Highly Optimal Economies, Optimized Muck Spam, Defending Buff Mucks Highly Optimal Economies There was a lot of talk about the possibility of nerfing the exponential component in the muck buff as well as removing the ability to self empower your own EC with that buff. While that was happening, my rankings were stonking (a colloquial term to refer to massive increases in stock price, or for Battlecode, massive increase in ELO rating). Eventually once I reached 2nd on the leaderboard, then the nerf came. This was followed by an instant drop in ranking as my strategy was well fine tuned to abusing the self empowerment strategies and muck buffs.\nDuring this period, a lot of the top bots shifted to focusing on developing a good economy with a few exceptions. Team Wololo being the standout exception in that their bot was at its core, a muck spam, but a very good one.\nFor most of the more eco focused bots, the development of a good economy relied on a good initial build queue as the first slanderers have the most profound effect on economy in the early game. From there came up several problems that are still quite difficult to approach.\nOne of these problems is deciding when to take a neutral EC. One thought is that taking it earlier means developing more units and theoretically a better economy. However, this is actually not the case all the time since some neutral ECs require bigger polis to empower and be controlled and as a result, this means you spend several turns stocking up on influence from slands generating influence, the opportunity cost being building more slands instead. So one would need to find some kind of pareto optimality of when to capture and when to keep building an economy. I ended up just forcing my bot to stock influence for a neutral EC always, but spend it beforehand if I am not generating enough influence yet, and once I get enough influence I\u0026rsquo;ll attempt an neutral EC capture. Other teams seem to have variations of this or just go for the neutral EC right away or wait until they have X amount of influence.\nBut there\u0026rsquo;s other problems associated with neutral EC captures. One common problem is that sometimes one team would capture a neutral EC, wasting their influence lowering neutral EC influence, and then another team would capture that EC, spending its influence lowering what is now the oposition team\u0026rsquo;s EC influence, which is far more efficient. As a result, some teams implement a strategy where they capture a netural EC if they don\u0026rsquo;t see an enemy poli or the enemy poli just captured the neutral EC and now they go for the more efficient capture.\nAnother problem is maintaining the economy by 1. continuously building slands and 2. protecting them from enemy mucks. These 2 problems form another tradeoff that one needs to find another pareto optimality of sorts and it just gets complicated from there. A combination of macro and good micro helps approach this and for the most part, team Malott Fat Cats does this the best and is certainly the most robust bot, having unfortunately succumbed to map RNG in the finals.\nOptimized Muck Spam Very few bots were capable of doing this well. Prior to qualifiers the best muck spam bot was by team java :ghosthug:. Closer to qualifiers team Wololo started their own variant of it with some very interesting heuristics that made it very effective. They used some form of force equation like Coulomb\u0026rsquo;s Law I believe to keep their mucks apart enough so they cannot get two bird one stoned by a single poli, while also helping them attack from many angles and expose the enemy slands and take control of games. Their bot relied on needing many EC turns and so they went for early neutral EC captures to then dominate the map and make it difficult for hard-eco bots to stop them.\nTeam Wololo\u0026rsquo;s bot was quite interesting and you can read it here: https://github.com/iliao2345/Battlecode2021\nBy far, it was the most unique bot amongst the top bots.\nDefending Buff Mucks I honestly don\u0026rsquo;t know what\u0026rsquo;s a good way to defend against wololo\u0026rsquo;s muck spam or buff mucks from high eco teams. My own strategy comprised of using a scouting network of units to shout locations of enemy mucks to my EC who then communicate that to surrounding slands to tell them to run away in a particular direction.\nI also actually shift the center point of my slands whenever they run away so that they don\u0026rsquo;t back to a location that previously was deemed too close to an enemy sland, which was difficult to determine if it helped or not. This effectively let enemy teams herd my slands away from my EC which kept them in generarl farther away from enemy units, but perhaps more susceptible to flanks.\nSomething else I should have added was letting any buff poli attack buff mucks. My bot so far only attacks buff mucks with designated buff polis that it built just for those buff mucks. All my other buff polis that usually go around to try and capture enemy ECs completely skipover buff mucks, and there have been many a time where this would have saved my slands and economy. This just further reiterates that time is so important in Battlecode.\nDefending is quite hard, despite being theoretically optimal to defend as opposed to attack with buff mucks as buff mucks waste 30% of the influence spent on them and only 70% is kept as conviction. Looking at the winning team\u0026rsquo;s code, team babyducks, their code for defending buff mucks is quite simple. If poli sees a nearby buff muck, they try to hunt it and once close enough, immediately empower. There a ton of optimizations that can be done e.g. empowering only when there arent too many units nearby that would dilute the empower and this is seen as a comment in their code. Moreover, they do only a simple local check for buff mucks to then spawn enough polis to have greater total conviction than the mucks, somewhat similair to my code only that I also consider buff mucks beyond the EC vision range. Definitely not perfect, but it\u0026rsquo;s good enough.\nIn typical Battlecode fashion, defence is hard, attack is easy, hence spam and rush bots tend to always surface in Battlecode.\nFinals - \u0026ldquo;Exponential\u0026rdquo; growth, Troll maps, Massive Upsets \u0026ldquo;Exponential\u0026rdquo; growth Towards the start of finals, some teams began to decide to massively boost their economy by building even more slands. This can be seen in teams like babyducks, Nikola, and mine, where we decided to build more slands than polis to create \u0026ldquo;exponential\u0026rdquo; income growths and expand our economy alot. Two income graphs of games between me (red) and team Wololo (blue). On the left I take very early control with a strong economy by building tons of slands. On the right, while I initially lose control, I keep regrowing the economy to do recovery growth and take win the game\nThis strategy has it\u0026rsquo;s downsides in that it\u0026rsquo;s risky. It\u0026rsquo;s very easy to lose slands. But I chose this strategy based on the fact that I assume if I build so many slands, I will have so much income that it won\u0026rsquo;t matter if I lose some and I\u0026rsquo;ll likely hit the other team\u0026rsquo;s economy hard. This turns out to be fairly RNG and map dependent, as well as requiring good muck defence and some better micro code, which unfortunately wasn\u0026rsquo;t the case with me as I lost to babyducks in the losers bracket of finals 5-0.\nThis was basically the last thing I changed with my bot and I basically had no more time to do any more tuning. Given the lack of time between qualifiers and finals, I cannot comment to much on other bots other than that the leading Malott Fat Cats could not improve their bot at all and other teams seemed to have made various changes that I didn\u0026rsquo;t get a chance to see until finals.\nTroll Maps and Upsets One of the many troll maps created by teh devs\nThe above map should resemble something familiar if you followed the news around this time. Yes, it is GameStop stocks stonking up. Historically maps in Battlecode are always meme like in nature or meant to mess with competitors while \u0026ldquo;keeping it balanced.\u0026rdquo;\nInterestingly, prior to finals, all tiles under all ECs had passability of 1 in all maps except one. Yet in finals, almost every map had ECs with lower passability which hurt some bots more than others.\nThis led to some of the upsets in the finals, namely Malott Fat Cats not even making it to the final finals. You can see the full progression of the finals bracket here: https://challonge.com/bc21_final/standings. There were also the expected potential upsets, with team Wololo known to be the wildcard and having actually defeated team babyducks in the very first round.\nNevertheless, watching team babyducks make their away from the very bottom of the losers bracket all the way to the top to win the entire tournament was amazing. It was fun to see all these different strategies come into play and watch bots make comebacks, to then start losing, to then suddenly do a reverse sweep and win. The number of close matchups this year is probably a record, so many matchups ended in 3-2, meaning either team could\u0026rsquo;ve won if map RNG was on their side.\nIn the end, babyducks persevered and won Battlecode 2021, congratulations to them!\nMy Evaluation It\u0026rsquo;s always hard to say if a game design is good or bad.\nIf the goal is to create excitement, hype, and a ton of interesting matches, then I\u0026rsquo;d say Battlecode 2021 was a great design. It created a lot of different unique problems teams had to solve such as defending buff mucks, scouting, capturing neutral ECs and tons more. The interplay of different solutions to different problems culminated in 16 teams in the finals creating wildly different results in each matchup.\nHowever, in terms of accessibility, as usual Battlecode does quite poorly. New competitors will find it very difficult to get started. Not only is bytecode usually a foreign concept to most, but the specs are quite long and it\u0026rsquo;s easy to get lost in them. The startup cost to get a bot working and submitted to servers is quite high with installation / setup instructions that are neither intuitive nor simple to follow, leading to many new competitors dropping the compettition early. Moreover, the lack of perfect information is almost always a blocker for new competitors as it\u0026rsquo;s difficult to code something for all your different units that can\u0026rsquo;t see each other or work together unless you use a very rudimentary communications system.\nAnother issue is the poor feedback in Battlecode. Comparatively to past years, games ran a lot slower making the time to feedback for how your code changes surface up in matches a lot longer and slowing development. This commonly frustrates competitors and adds to that startup cost as people have to adapt to the slowness. Another major issue is the visualizer giving very poor visual feedback on important things that competitors wanted to know about, e.g. unit influence / conviction, how far a poli empowered etc. This made debugging a lot more difficult and made the gulf of evaluation grow ever so larger. However, given the required style of Battlecode, it\u0026rsquo;s difficult to make an efficient game and visualizer, and to have gotten this far already is quite a feat.\nFortunately, in my opinion, a good turning point from last year is the reduction in units, which also has it pros and cons. Primarily, this makes coding a lot simpler and makes it easier to comprehend. Too many units and the action space becomes ridiculously large, which helps expand the space for strategy, but at a severe cost of understanding and good system images to help connect the competitor\u0026rsquo;s conceptual models with the correct conceptual model of the game.\nDespite less units and a smaller action space than previous years, the mechanics of this year\u0026rsquo;s game still enabled a wide variety of strategies, although mostly difficult to see on a macro scale. One of the more interesting designs of this year is the power to take control of opposition units and use them yourself through poli empower abilities. This invited the potential for a ton of strategies that I think could be employed if teams were given more time.\nAnother interesting feature is the ability to variably decide the influence and conviction of a unit upon building it. This allowed for things like buff mucks to become a big part of the competition, but in my opinion this just added unecessary difficulty and complexity that wasn\u0026rsquo;t that interesting. The same can be said for the whole bidding for votes feature. Having to optimize bids and unit sizes based on incomplete information is definitely an interesting problem, but not something I would try to deal with in only 3 weeks. Many teams in fact didn\u0026rsquo;t even bother with the bidding mechanic of the game at all until very late into the tournament, with many teams believing it to be fairly suboptimal to bid and the only reason you would bid would be to prevent yourself from accidently losing to teams who actually bid for votes and somehow dodge all your units.\nWhen a design ends up becoming pure optimization using the same features every other team uses, it can become quite dull. Luckily in Battlecode, there are a high number of features and local / communicated information that can be used to aid in optimization that make it quite fun and interesting to analyze. This helps further make the variable influence / conviction not too bad of a design, but perhaps a bit of an annoyance.\nSome statistics Final bot contained 2908 lines of code with 395 lines of comments. I made 191 commits. The max commits in a single day is 23.\n🌊\n","permalink":"https://blog.stoneztao.com/posts/bc21/","summary":"Battlecode 2021 Postmortem This is my 4th year competing in MIT Battlecode. I previously competed as Bowl of Chowder (5th) in 2020, and as Codelympians (9th) in 2019 and was Codelympians in 2018 but did not make finals the first year.\nThis year I once again soloed my way to finals, achieving 9th overall, and to my surprise, won the \u0026ldquo;Adaptive Strategy\u0026rdquo; award for spearheading the development of a strategy known as \u0026ldquo;muck flanking.","title":"Battlecode 2021 Postmortem"},{"content":"The Beauty and Brilliance of Tales From the Loop I recently just finished watching the first season of Tales From the Loop after having also bought the original artbook mid-way through the season because of how \u0026ldquo;entranced\u0026rdquo; I was by the concept and art. Tales From the Loop was originally an artbook by Simon Stålenhag and it\u0026rsquo;s truly mesmerizing. In this post, I talk about his art, and then the story and show that grew from the art.\nA brief bit of context, \u0026ldquo;The Loop\u0026rdquo; was a fictional underground research facility comprised of a particle accelerator for experimental physics, and it produced a number of \u0026ldquo;artifacts\u0026rdquo; that are left unexplained, but there for the world to interact and experience with.\nThe Art Original book\u0026rsquo;s cover art\nHis art forms a beautiful intersection of the ordinary with the extraordinary. Best of all, none of the extraordinary is explained.\nSounds crazy, but really, it\u0026rsquo;s beautiful.\nAnd if you don\u0026rsquo;t like the way I put it, see the art for yourself, or this post from Scientific American, or this post from The Verge.\nDespite being a typical knowledge-hungry student, I\u0026rsquo;m actually happy that Tales From the Loop leaves every mystery unexplained and learned a few things from that.\nWhen I was younger my mom forced me to go to a ton of art museums because she likes art (and is an amazing artist herself) and I guess she believes exposure to art is an important part of my upbringing. I disliked most of the trips, hated the lack of benches, and most of the time asked the same question: \u0026ldquo;why is the art so expensive?\u0026rdquo; (Now that I think of it, the lack of benches encouraged me to stand and walk more, forcing me to view the art instead of sitting down and dozing off or looking at my phone, an interesting design; reminds me of this great vox video on uncomfortable benches)\nIt takes time to understand art at a deeper level, but time has passed and now one thing I did take out of all of those art museums is that a lot of meaning and beauty of art stems from how you interpret it, how you want the story to be told. I\u0026rsquo;m no art expert myself but I think the beauty of it is that you can have your own \u0026ldquo;meta\u0026rdquo; interpretation of art in general, and the art will have succeeded in curating thought and inspiration possibly.\nStrange towers and spheres, and an unaffected suburban vibe\nMy own interpretation of Stålenhag\u0026rsquo;s art stems from the similar vision the writers and producers and composers of the series had, and that the true story doesn\u0026rsquo;t lie within the fantastical elements, but how the fantastical elements interact with the ordinary and cultivate human relationships, feelings, and story.\nThe show captures this vision completely. With the help of a strong, artistic basis, writer / producer Nathaniel Halpern and composers Phillip Glass and Paul-Leonard Morgan were able to turn static photos into a breathtaking series of episodes.\nThe Show Every single episode has some artifact that underpins the story of that episode. We\u0026rsquo;re never told how that artifact works, we only see how the events unfold.\nRuss Willard and his Grandson Cole visit the Echo Sphere. Context: Russ is the director at The Loop and his whole family basically works there\nIn the picture above, the Echo Sphere was a device leftover from old experiments that estimated how much time you have left in your life through the number of echos. When Russ didn\u0026rsquo;t get a single echo back and told Cole the sphere wasn\u0026rsquo;t broken, my heart sank. I\u0026rsquo;ve already forgotten about the intriguing behavior of the echo sphere, and already directed my attention to the grandfather grandson relationship Russ and Cole had.\nNow imagine watching several of these moments each episode unfold over the course of a season.\nDespite Cole and his family being a bit of the \u0026ldquo;center-piece\u0026rdquo; of this show, the show also follows the stories, the loops, of other individuals as well. In the third episode, May initially wishes for special moments to last forever, of which she \u0026ldquo;solves\u0026rdquo; by building a time stopping machine that stops time for everyone without a special bracelet.\nMay and Ethan talk while time for everyone else is stopped\nYet despite stopping time for a long time, the relationship between May and Ethan turns sour and it ultimately ends with Ethan dropping his bracelet, freezing Ethan in time. May is forced to unstop time and learns that moments are special because they do not last. May echos another common theme throughout the show: there are no second chances, you have to come to terms with whatever happens, and this speaks to the amazing realism of the show.\nLike May, Cole has to come to terms with the due course of nature, and unfortunately for Cole, he faces this many, many times, from his grandfather\u0026rsquo;s passing to his brother\u0026rsquo;s conscience being swapped into a robot that breaks down in the final episode.\nThis also speaks to the generalizability of the core concepts behind Tales From the Loop. Tales From the Loop provides a structure that allows the creators to use different perspectives and stories to convey the same motifs. There are a myriad of other sublteties that elevate the art and show to astounding levels of meaning and depth, and I haven\u0026rsquo;t even gotten to the music powering the evocative periods of silence in the epiodes. For the sake of brevity, I stop here, and recommend you watch the show yourself because my words alone are not enough to capture the beauty of Tales From the Loop completely.\nThrough Stålenhag\u0026rsquo;s art and the unbelivable show, I learn that I have to come to terms with what\u0026rsquo;s given, my actions, and other\u0026rsquo;s actions, and the force of nature. Sometimes the mysteries aren\u0026rsquo;t meant to be explained, we are there to just witness the phenomena.\nI really hope there is a second season, but it\u0026rsquo;s probably the end of the loop for this story. Perhaps another timeline can create a similar undefinable feeling that Tales From the Loop gives.\nIt was brilliant.\n🌊\n","permalink":"https://blog.stoneztao.com/posts/talesfromtheloop/","summary":"The Beauty and Brilliance of Tales From the Loop I recently just finished watching the first season of Tales From the Loop after having also bought the original artbook mid-way through the season because of how \u0026ldquo;entranced\u0026rdquo; I was by the concept and art. Tales From the Loop was originally an artbook by Simon Stålenhag and it\u0026rsquo;s truly mesmerizing. In this post, I talk about his art, and then the story and show that grew from the art.","title":"The Beauty and Brilliance of Tales From the Loop"}]
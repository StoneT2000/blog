<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>High Precision Function Approximation With Decision Trees and Neural Networks | Stone's Blog</title><meta name=keywords content="AI,Decision Trees"><meta name=description content="While at QuantCo, I worked on a function approximation problem with high dimensionality and many discontinuities. I introduce some of our work that tackles these problems using decision trees, neural networks, and more."><meta name=author content="Stone Tao"><link rel=canonical href=https://canonical.url/to/page><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.67fc9647a5c3b1af337010c7ac35cd071958b1c9e0c69661ef1a83071332f18b.css integrity="sha256-Z/yWR6XDsa8zcBDHrDXNBxlYscngxpZh7xqDBxMy8Ys=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://blog.stoneztao.com/logo512.png><link rel=icon type=image/png sizes=16x16 href=https://blog.stoneztao.com/logo512.png><link rel=icon type=image/png sizes=32x32 href=https://blog.stoneztao.com/logo512.png><link rel=apple-touch-icon href=https://blog.stoneztao.com/logo512.png><link rel=mask-icon href=https://blog.stoneztao.com/logo512.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="High Precision Function Approximation With Decision Trees and Neural Networks"><meta property="og:description" content="While at QuantCo, I worked on a function approximation problem with high dimensionality and many discontinuities. I introduce some of our work that tackles these problems using decision trees, neural networks, and more."><meta property="og:type" content="article"><meta property="og:url" content="https://blog.stoneztao.com/posts/nn-fnc-approx/"><meta property="og:image" content="https://blog.stoneztao.com/%3Cimage%20path/url%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-12-15T11:30:03+00:00"><meta property="article:modified_time" content="2021-12-15T11:30:03+00:00"><meta property="og:site_name" content="Stone's Blog!"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blog.stoneztao.com/%3Cimage%20path/url%3E"><meta name=twitter:title content="High Precision Function Approximation With Decision Trees and Neural Networks"><meta name=twitter:description content="While at QuantCo, I worked on a function approximation problem with high dimensionality and many discontinuities. I introduce some of our work that tackles these problems using decision trees, neural networks, and more."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.stoneztao.com/posts/"},{"@type":"ListItem","position":2,"name":"High Precision Function Approximation With Decision Trees and Neural Networks","item":"https://blog.stoneztao.com/posts/nn-fnc-approx/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"High Precision Function Approximation With Decision Trees and Neural Networks","name":"High Precision Function Approximation With Decision Trees and Neural Networks","description":"While at QuantCo, I worked on a function approximation problem with high dimensionality and many discontinuities. I introduce some of our work that tackles these problems using decision trees, neural networks, and more.","keywords":["AI","Decision Trees"],"articleBody":"High Precision Function Approximation With Decision Trees and Neural Networks While I interned at QuantCo, I worked on a kind of crazy project with my (amazing) advisor Ben Thompson, titled “The Deep Neural Net Function Approximation Project”. Here’s the problem (with sensitive information stripped):\nOne of the clients is currently migrating a system. Written in C, it comprises of a ton of data and a ton of different functions, many of which are high-dimensional and full of discontinuities. QuantCo has been tasked to help the client migrate all of that to a new system using python and onto the cloud to make it more efficient, faster, and secure. However, the client estimates it would take about 100 person-years to complete due to the complexity of the system, the immense amount of math, and the immense amount of functionality and code that need to be migrated. Luckily, QuantCo has already reduced that work to less than 1 person-year. But can we do this even faster? Could we somehow automate code migration and reduce the time even further?\nInitially, this sounds like an impossible problem. Luckily, there are a few important things to note.\nThe client doesn’t care what the migrated code is like; they simply expect that historical data plugged into the migrated functions produce the same values to within some max acceptable error. We have the old system at our disposal. We can run it whenever we want. tldr; points 1 and 2 allow us to almost automate code migration. Point 1 means we can treat it as solving a difficult regression problem. Our approach then lets us use both points to turn code into matrices with a decision tree neural net (DTNN) model that is horizontally and vertically scalable. There’s also a bunch of strange / interesting use cases ranging from security to function compression to differentiating anyone’s code (even if it doesn’t really do any math).\nNow here’s a more formal statement:\nGiven some target function $f: \\mathbb R^n \\to \\mathbb R^m$, approximate $f$ with another function $\\hat{f}$ so that $\\hat{f}(x) = \\hat{y}$ is as close as possible to the ground truth $f(x)$. You are allowed to use $f$ to generate as many noiseless $(x, y)$ samples as you would like.\nThis function $f$ in our case is actually a giant file of code.\nThe above problem statement may seem somewhat trivial and seem like a typical regression problem, but there are a lot of hidden hazards that increase the difficulty immensely.\nThe target function we’re approximating is extremely discontinuous and complicated. This arises from the fact the function will completely change behavior when certain inputs change. In our project, the target function is a super large, handwritten calculator that computes some value given some inputs. In this calculator, there are various if statements, matrix products, string manipulations, array slicing, every arithmetic operator, and even reading data from data files that contribute to the outputs.\nThis means the majority of the classical regression models and any function approximation methods will almost certainly fail at regions of discontinuity in the target function, but for our problem, we need to make sure every single data point is approximated to within 1 of its true value. Moreover, different smooth regions in the target function all behave potentially completely different (one might be $e^x$, another might be $x^2- 3|x|$ all of a sudden)\nAdditionally, the target function produces values in the range of 1e5 to 1e7, which means our function approximator needs to achieve a precision of around 1e-5 to 1e-7 to pass.\nLastly, the target function has a high input and output dimensionality, both of which are in the order of 100s. This adds difficulty for any kind of model and slows down training and decreases accuracy. Additionally, we can’t apply any kind of feature selection and / or dimensionality reduction without the potential loss of information necessary for producing accurate output values.\nIn a nutshell, we solve a difficult regression problem, but there are a number of quirks in our case, namely\nWe have an oracle $f$​ (also our target function) that can generate noiseless groundtruth $(x, y)$​​ pairs on the fly. $f$​ is extremely discontinuous and changes a ton around discontinuities We need to achieve a high degree of precision on the orders of 1e-5 to 1e-7 $f$ also has 100s of dimensions in its input and output spaces Because of these quirks, many approaches have been investigated, and I’ll go in depth in the following 4\nNeural Networks 2nd order optimization of Neural Nets for regression Residual-based splitting Decision Trees + Neural Nets (DTNN) These proved to be the most influential and powerful methods out of all the other tricks and techniques we experimented with.\nNeural Networks Why deep neural nets for an approximation problem?\nIf we first consider the naive approach of storing a bunch of pre-computed pairs $(x, f(x))$​​ for all $x$ values in the historical data, we would have a perfect approximator. However, there not only is a ton of historical data (likely on the scale of petabytes), using this as a function to then retrieve a value for a given $x$​​ would take an unreasonably long time. Supposing you used some kind of nearest neighbor weighting model and stored a fraction of the historical data values and reduced the search time to find the $k$ nearest data points necessary for interpolation to reasonable milliseconds, then the accuracy worsens significantly.\nNow suppose we first ignore the discontinuities in our target function, we otherwise have very little information about what the target function is like without having to dive deep into the function’s code itself or doing significant data analysis on an extremely complex function. So most attempts to tackle this like a data science problem end up failing here. We need something that is flexible and can capture almost arbitrary patterns in the data.\nLuckily, since the client only cares that all historical data when passed through the approximated function are correct, we don’t need to worry about extrapolation, so potentially interpolation algorithms can come into play. We could generate many interpolation points and use interpolation algorithms such as polynomial interpolation, which in fact get really good approximations. Unfortunately, interpolation algorithms cannot scale when the dimensions increase and they begin to have impossible memory requirements after about as little as 5 dimensions for our particular target function. Trading off accuracy for lower memory requirements is also unfortunately very poor.\nDeep neural nets on the other hand are flexible function approximators and scale much better with dimensions in terms of both memory and compute, and arguably compress information much better than the interpolation algorithms at the cost of spending time training.\nThe typical way to use neural nets in a regression problem is to train the neural net over a lot of training data, constantly evaluate it on a held-out validation dataset and select the model that achieves the lowest loss on the validation dataset. In particular, the loss function is the MSE loss function and the optimizer that worked best was Adam. I won’t explain much in detail here, but tanh activation turns out to be the best and outperforms any non-smooth activation like ReLU significantly.\nHowever, standard neural networks on their own are nowhere near sufficient to achieve any level of desirable accuracy in our project, and the next section discusses the first massive improvement in performance via 2nd order optimization.\n2nd Order Optimization Almost ubiquitously, deep learning practitioners rely on first-order optimization algorithms such as Gradient Descent, Adam, RMSProp to name a few. These methods prove incredibly useful in many tasks because they are fast, computationally efficient and feasible, often bug-free, and many other reasons listed out in this stackoverflow answer. Another important aspect of first-order methods is that they achieve low generalization error compared to second-order methods, making algorithms like SGD and Adam incredibly popular in CV and NLP tasks where generalization error is paramount.\nHowever, some of these aspects are not a problem in our project. Generalization error is less of an issue since we can generate infinite, noiseless data, with the same distribution as test data, and in fact we can control the generalization error by tuning how much data is fed to the model at training time. In a future section when I discuss about the DTNN model, we also don’t need as much data as you think to be generated to ensure low generalization error. For similar reasons, in the DTNN model the neural networks trained are generally quite small, so we don’t have an issue of scale faced by 2nd order optimization of large neural networks.\nThese features of our project suddenly make 2nd order optimization algorithms much more feasible. Since we want to achieve an extremely high level of precision, 2nd order optimization actually becomes necessary.\nL-BFGS proves to be a very capable and feasible 2nd order algorithm that ended up being used throughout this entire project. The following graph shows as a function of time (s), how L-BFGS compares to Adam, a 1st order method when trying to fit the function $\\cos(20x)$​ over $x \\in [-1, 1]$ with a small neural network (~40 parameters). The data generated and fed into the neural network mimics that of the actual project. Very quickly L-BFGS converges to a low loss and outperforms Adam considerably.\nWith 2nd order optimization, a single deep neural net was able to achieve about 30% accuracy on test data in the project, meaning it predicted 30% of data points to within 1 of its true value. But this is about as far as it will go, and can’t scale farther in any direction (model complexity, time, data etc.) without entering scaling problems or hitting a minimum. The major issue is that discontinuities reduce the performance of the neural net as it attempts to fit a smooth model over it, in addition to having major approximation errors around the discontinuities. I tackle this issue next.\nResidual-Based Splitting\"\u003eResidual-Based Splitting We can treat any arbitrary function like our target function as being some piecewise smooth function if you split the input space into the right regions. So one solution is to identify the smooth regions of the input space and train a different function approximator that can achieve high precision and doesn’t need to worry about fitting to discontinuities. Thus, the fundamental reason for using a Decision Tree for this problem is to handle discontinuities.\nBefore diving into how a DT and NN work together, let’s first look at the splitting algorithm that drives it.\nTo understand how the splitting works to find discontinuities, I’ll demonstrate it on a simple one-dimensional discontinuous sine dataset which is shown below.\nThere’s a clear jump discontinuity at around x = 56 which would cause regression to be difficult! But let’s do a bit of overkill and try fitting a tanh activated neural network with L-BFGS to this data, we generate the following predictions (orange) compared to the ground truth (blue)\nNotably, we observe that on the smooth parts of the dataset, the neural network more or less fits it well. However, as we approach the discontinuity the predictions begin to vary a lot and we can see that the neural net attempts to make a smooth connection between the start and end of a discontinuity. Visually it’s clear where the discontinuity is, and we can identify this algorithmically by using residuals, which is equal to prediction - ground_truth, and when we plot the residuals we get\nThe residuals are a strong signal of where the model has fitted well and where it hasn’t. We can see that the residual magnitude is near 0 on smooth parts, and increases significantly near the discontinuity. We can then clean up this signal further by taking the top 99th percentile of residuals by magnitude, leaving us with the following data points. The red dashed line represents the location of the true discontinuity.\nWe observe now that amongst the largest residuals, residuals increase in magnitude in the negative direction as we approach the discontinuity before suddenly flipping in sign and decreasing in magnitude as we move away from the discontinuity. This is something that will often happen when fitting smooth models like a neural network with smooth activation to the discontinuity as the model attempts to find a smooth transition around the discontinuity. However, as a result, the residuals will have a sign flip and / or a large increase in magnitude around the discontinuity.\nA direct algorithmic way to then find this discontinuity is to use the splitting algorithm regression DTs use, which is finding a split on one of the input dimensions that minimizes the mean squared error of the 99th percentile residuals. Visibly, we can see that such a split would minimize the MSE by splitting near the discontinuity. This serves as a rather crude (but surprisingly effective) approach to identifying residuals with minimal overhead.\nThere can be a lot of further research on discontinuity finding to improve this, from refining a split decided by a DT by generating more data near the split or finding other algorithms that discover and can ignore the noise potentially introduced by poor-fitting in other input space regions, in addition to being more effective in higher dimensions where discontinuities in other dimensions or spanning multiple dimensions can make this much more complex.\nDTNNs Now that we have in our toolbox a neural network-based function approximator and a method to identify discontinuities and separate out the smooth regions in the input space, we can combine these into a single decision tree neural network model. This combination then allows us to also make effective use of a key property of this problem, which is that we can generate data on the fly using the target function.\nAt a high level, a DTNN is a decision tree with neural nets at each leaf that perform the regression for any data that falls to that leaf, and the splitting algorithm is the residual-based splitting method. Thanks to the splitting of the input space, we also don’t need as much data or as big of a neural network model at each leaf to sufficiently capture the behavior there with high accuracy.\nGrowing the DTNN The growing algorithm is quite similar to a typical decision tree growing algorithm but with a few changes. The DTNN maintains the same procedure of taking each leaf node and determining first whether to continue splitting, then deciding on the best split to make before making the split.\nOne key difference is that every leaf has an associated neural network that does the prediction for all data that falls into that leaf’s data range (the subset of the input space it represents). Note that each leaf is associated with a disjoint subset of the input space of the target function, and the union of all these disjoint subsets forms the entire input space (up to the boundaries set for interpolation).\nFor leaf node splitting, the residual-based splitting method introduced earlier is used and the residuals are computed using the trained neural net associated with the leaf. Importantly, since we can generate infinite data, this model can become infinitely precise to the point it memorizes every input output pair via splitting the input space into extremely data ranges. Thus, we only split leaf nodes where the neural network trained there is not accurate enough. Ideally, this neural network reduces the need to memorize every value and learns a good approximation with fewer parameters.\nFor each new leaf produced after splitting an old leaf, we create a new associated neural net. These new neural nets are copies of the neural net associated with the old leaf, helping speed up training with a warm start.\nLastly, we regenerate data in each new leaf, using randomly selected inputs data points that fall within the new leaf’s data range, and train the neural net on that new data.\nVisually, growing a DTNN looks like this:\nA green circle represents a leaf node that has a trained neural network that is accurate enough, a blue node is an internal node or a to be trained leaf node. Each round, we increase the depth of the tree by one via residual-based splitting and only generate two children per leaf node, and then fine tune the neural nets at all leaf nodes that need fine tuning.\nDTNN Pseudocode For those who prefer pseudocode, the growing algorithm is as follows\ndef DTNNGrow(rounds, train_net, data_generator, pass_criteria, splitting_func, input_subspace): root_node := initialize a DTNN with a empty root node associated with input_subspace leafs_to_train = { root_node } passing_leafs = {} for round = 1 to round = rounds: if leafs_to_train is empty: return root_node for leaf in leafs_to_train: # generate data within the subset of the input space of data that falls in the leaf train_data, test_data := data_generator(leaf.data_range) if leaf has a parent node: neural_net := copy of neural net in parent node else: neural_net := initialize a new neural net # train a NN until its good enough or until some max iterations train_net(neural_net, train_data, test_data) remove leaf from leafs_to_train if pass_criteria(neural_net, test_data): add leaf to the set passing_leafs else: # split the subspace of the current leaf based on the trained NN and train_data data_ranges := splitting_func(neural_net, train_data, leaf.data_range) for data_range in data_ranges: new_leaf := initialize a new leaf node associated with data_range add new_leaf to the set leafs_to_train return root_node We grow the DTNN in rounds, with each round increasing the depth of the DTNN by 1. To train, you provide the number of training rounds, a neural net training function, the data generator, a pass criteria function, and a splitting function.\nThe neural net training function train_net should take a neural net, training data, and test data generated from the data_generator that is within a leaf’s data range, and train that neural net. Usually, this stops training when the neural net is accurate enough, or when it is training for too long.\nThe data_generator will usually be a wrapper function around the target function we want to approximate where it takes a data range and produces training and test data that is within that data range. Our experiments used uniform sampling across each input dimension of the data range, but I actually recommend using something akin to farthest point sampling (common sampling technique in 3D computer vision like sampling point clouds).\nThe pass_criteria function will evaluate a neural net over the given test data and would return true if the neural net is good enough and false otherwise. This function is important since the data is noiseless and infinitely generatable, so theoretically you can always keep improving but we need to stop eventually.\nThe splitting_func is a function that when given the neural network, the training data, and the data range the training data is generated from, returns the new data ranges for all new leaves. An example would be the residual-based splitting method.\nThe input_subspace is simply the data range of inputs that we want to approximate the target function over, and the root node of the DTNN is associated with this input subspace. For our project, this would be the boundaries of every feature dimension in the historical data.\nDTNN Discussion Results With the DTNN and residual-based splitting and 2nd order optimization, we raised that 30% to about 86% of test data points approximated to within 1, despite data points being on the order of 1e5 to 1e7. In particular, the single NN and DTNN were both trained on a single CPU for 64 hours and achieved 30% and 86% accuracy respectively. This outperforms just about any regression model we tried, from GBDTs (~2% accuracy), to first-order optimized neural nets (~2% accuracy), to interpolation algorithms (infeasible).\nThe major reason the DTNN achieves such a massive improvement is in addition to 2nd order optimization, it also can effectively leverage the data generating aspect of the problem in an efficient distributed manner via a decision tree structure. Intuitively, each split at a leaf reduces the data range for the new leaves, meaning less data is necessary to be kept around in memory to achieve low generalization error, and effectively optimize a neural network as well. Models that can’t leverage the data generation will have to rely on generating a huge amount of data that can barely fit in memory or augmenting data every round. Even with some kind of data generation mimicking that of the DTNN where data is effectively generated for leaves that need more training / high error regions in the input space, models like single neural nets will need to not only be massive, but also somehow solve the issue of catastrophic forgetting.\nThe DTNN also has a number of nice properties. One is that it is highly scalable compared to neural networks, another is that it has unbounded performance potential with no generalization problems (usually). There are a bunch more but these are listed in the further applications section. There’s also a further research topic section that lists out a number of questions my advisor and I asked that we didn’t have time to explore but are probably worth exploring and can improve the results.\nScaling You can easily parallelize the DT growing process by training each leaf on a separate core, subject to balancing issues if there are only 2 leaves training and one takes a lot longer than the other. Moreover, this project is more often CPU bottlenecked as the target function tends to be the main limiting factor due to data generation speeds, so GPUs aren’t really necessary (nor are 2nd order optimization methods that well optimized on the GPU), so in terms of scaling, you can simply increase the number of CPUs (generally quite easy) and achieve pretty high efficiency in training speed vs number of CPUs used.\nYou can even horizontally scale this process across multiple servers probably, although I’m not exactly sure how much of an overhead that might have. I suspect it should be fairly low since the only unique data each different server has is the data range and the neural network, everything else is the same from the target function / data generator, to the neural network architecture and splitting function.\nUnbounded Potential In theory, with a target function at hand to generate noiseless training data, the DTNN can get 100% of training and test data points approximated to not just within 1, but even 0.1, 0.01, etc. when given sufficient time, a guarantee that cannot be said of any other model that I’m aware of (except for an extremely, out of memory, DT kind of model which at that point is really just memorizing the training data).\nThis is thanks to the fact that the test data will always be “in distribution” since it’s generated from the same function as the training dataset (and generally mimics the historical data the client has). As long the neural network at each leaf is given sufficient data points, it will have minimal to no generalization error.\nMoreover, every split on the data range makes training neural nets easier and easier as you effectively cut the hard part of the regression problem out and leave just the smoother regions of data. This is an easy direct way of adding parameters to the model to boost performance without making a neural network bigger and scales linearly with each leaf added.\nFurther Applications In addition to just solving the formal problem of approximating a target function with high accuracy and precision, there are a number of other applications of this since we effectively turn lines of code that form the target function into matrices! Here is a non-exhaustive list of some of these applications\nFunction compression: Reduce the amount of space required for purpose of approximation. Moreover, the calculator that was being approximated in my project actually pulls data from various tables and the neural nets are capable of removing the need for that data and bake that information into their model parameters Faster computations: speed up an existing function with a faster model that approximates it. Easily trading off accuracy for speed. Differentiation: Differentiate a handwritten function for analysis purposes. Derivative information is often useful for many problems such as optimization. My advisor had the idea of potentially trying to determine which other calculators in our client’s old system were most similar to the one we approximated and first-order information would be helpful in determining this. Portability: A decision tree and their neural networks can be easily packaged as some matrices in a single data file which can easily be run anywhere without needing access to sensitive files and data. Security: A file containing just matrices makes people very comfortable compared to a calculator with 1000s of lines of code and poses a minimal security risk should these matrices get stolen as business logic cannot be read from them. Further Research Topics We faced a number of interesting problems in an effort to approximate our target function, all of which may benefit from additional research to improve training time, accuracy etc.\nHandling discrete/continuous: Discontinuity finding may differ when the input dimension is discrete or continuous. Perhaps some kind of bisection search method may find the true discontinuity with high precision and accuracy or using some form of refinement procedure to fine tune a split on a continuous axis.\nNon-linear/non-axial discontinuities: In higher dimensions, discontinuities may not be axial and may be non-linear. While these discontinuities can sometimes be approximated by several axial/linear splits on the input data space range, there are likely more efficient methods that allow for non-linear splits that can cover a wider range of potential discontinuities. One method might be to replace the splitting function with a neural net trained to perform “split classification”. Not only does this enable non-linear splits, but it would also make the entire DTNN model end to end learnable and differentiable which could have potentially interesting results.\nData generating given non-linear/non-axial splits: Supposing the above problem was dealt with and we now have a splitting function that effectively classifies a data point as being one of k classes. How do we generate data for each of these classes?\nAdaptive data generation: When not enough data is provided for training, a model will get a high generalization error which is not desirable. However, when too much data is provided, the marginal improvement in generalization error is likely not worth the amount of extra training time required. Thus, there is probably some kind of optimal data generation amount at each leaf of the DTNN.\nAdaptive early stopping: Notably, just increasing the total number of training iterations per leaf does not necessarily correlate with a better model when training for the same total amount of time as a model can begin to struggle due to discontinuities. Empirically, too many iterations makes the model spend too much time trying to approximate discontinuities when it is better off performing a split first, then training for much longer. Can we somehow optimally determine when to perform a split to deal with discontinuities?\nClosing Notes I had a great time at QuantCo and working with my advisor on this problem. If you are ever interested in the craziest engineering, machine learning, data science, etc. problems, pay them a visit. Or if you like good company and food, they’re also a great place.\n🌊\n","wordCount":"4570","inLanguage":"en","image":"https://blog.stoneztao.com/%3Cimage%20path/url%3E","datePublished":"2021-12-15T11:30:03Z","dateModified":"2021-12-15T11:30:03Z","author":{"@type":"Person","name":"Stone Tao"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.stoneztao.com/posts/nn-fnc-approx/"},"publisher":{"@type":"Organization","name":"Stone's Blog","logo":{"@type":"ImageObject","url":"https://blog.stoneztao.com/logo512.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.stoneztao.com/ accesskey=h title="Stone's Blog (Alt + H)"><img src=https://blog.stoneztao.com/logo512.png alt aria-label=logo height=35>Stone's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://blog.stoneztao.com/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://blog.stoneztao.com/tags/ title=tags><span>tags</span></a></li><li><a href=https://stoneztao.com title="Main Page"><span>Main Page</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.stoneztao.com/>Home</a>&nbsp;»&nbsp;<a href=https://blog.stoneztao.com/posts/>Posts</a></div><h1 class=post-title>High Precision Function Approximation With Decision Trees and Neural Networks</h1><div class=post-description>While at QuantCo, I worked on a function approximation problem with high dimensionality and many discontinuities. I introduce some of our work that tackles these problems using decision trees, neural networks, and more.</div><div class=post-meta><span title='2021-12-15 11:30:03 +0000 +0000'>December 15, 2021</span>&nbsp;·&nbsp;22 min&nbsp;·&nbsp;Stone Tao&nbsp;|&nbsp;<a href=https://github.com/StoneT2000/blog/tree/main/content/posts/nn-fnc-approx/index.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=lazy src=https://blog.stoneztao.com/%3Cimage%20path/url%3E alt><p></p></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#neural-networks>Neural Networks</a></li><li><a href=#2nd-order-optimization>2nd Order Optimization</a></li><li><a href=#residual-based-splittingresidual-based-splitting>Residual-Based Splitting">Residual-Based Splitting</a></li><li><a href=#dtnns>DTNNs</a><ul><li><a href=#growing-the-dtnn>Growing the DTNN</a></li><li><a href=#dtnn-pseudocode>DTNN Pseudocode</a></li><li><a href=#dtnn-discussion>DTNN Discussion</a></li></ul></li><li><a href=#further-applications>Further Applications</a></li><li><a href=#further-research-topics>Further Research Topics</a></li><li><a href=#closing-notes>Closing Notes</a></li></ul></nav></div></details></div><div class=post-content><h1 id=high-precision-function-approximation-with-decision-trees-and-neural-networks>High Precision Function Approximation With Decision Trees and Neural Networks<a hidden class=anchor aria-hidden=true href=#high-precision-function-approximation-with-decision-trees-and-neural-networks>#</a></h1><p>While I interned at <a href=https://quantco.com/>QuantCo</a>, I worked on a kind of crazy project with my (amazing) advisor <a href=https://tbenthompson.com/>Ben Thompson</a>, titled &ldquo;The Deep Neural Net Function Approximation Project&rdquo;. Here&rsquo;s the problem (with sensitive information stripped):</p><p>One of the clients is currently migrating a system. Written in C, it comprises of a ton of data and a ton of different functions, many of which are high-dimensional and full of discontinuities. QuantCo has been tasked to help the client migrate all of that to a new system using python and onto the cloud to make it more efficient, faster, and secure. However, the client estimates it would take about 100 person-years to complete due to the complexity of the system, the immense amount of math, and the immense amount of functionality and code that need to be migrated. Luckily, QuantCo has already reduced that work to less than 1 person-year. But can we do this even faster? Could we somehow automate code migration and reduce the time even further?</p><p>Initially, this sounds like an impossible problem. Luckily, there are a few important things to note.</p><ol><li>The client doesn&rsquo;t care what the migrated code is like; they simply expect that historical data plugged into the migrated functions produce the same values to within some max acceptable error.</li><li>We have the old system at our disposal. We can run it whenever we want.</li></ol><p><strong>tldr;</strong> points 1 and 2 allow us to almost automate code migration. Point 1 means we can treat it as solving a difficult regression problem. Our approach then lets us use both points to turn code into matrices with a decision tree neural net (DTNN) model that is horizontally and vertically scalable. There&rsquo;s also a bunch of <a href=#Further-Applications>strange / interesting use cases</a> ranging from security to function compression to differentiating anyone&rsquo;s code (even if it doesn&rsquo;t really do any math).</p><p>Now here&rsquo;s a more formal statement:</p><p>Given some target function $f: \mathbb R^n \to \mathbb R^m$, approximate $f$ with another function $\hat{f}$ so that $\hat{f}(x) = \hat{y}$ is as close as possible to the ground truth $f(x)$. You are allowed to use $f$ to generate as many noiseless $(x, y)$ samples as you would like.</p><p>This function $f$ in our case is actually a giant file of code.</p><p>The above problem statement may seem somewhat trivial and seem like a typical regression problem, but there are a lot of hidden hazards that increase the difficulty immensely.</p><p>The target function we&rsquo;re approximating is extremely discontinuous and complicated. This arises from the fact the function will completely change behavior when certain inputs change. In our project, the target function is a super large, handwritten calculator that computes some value given some inputs. In this calculator, there are various if statements, matrix products, string manipulations, array slicing, every arithmetic operator, and even reading data from data files that contribute to the outputs.</p><p>This means the majority of the classical regression models and any function approximation methods will almost certainly fail at regions of discontinuity in the target function, but for our problem, we need to make sure <strong>every single</strong> data point is approximated to within 1 of its true value. Moreover, different smooth regions in the target function all behave potentially completely different (one might be $e^x$, another might be $x^2- 3|x|$ all of a sudden)</p><p>Additionally, the target function produces values in the range of 1e5 to 1e7, which means our function approximator needs to <strong>achieve a precision of around 1e-5 to 1e-7</strong> to pass.</p><p>Lastly, the target function has a high input and output dimensionality, both of which are in the order of 100s. This adds difficulty for any kind of model and slows down training and decreases accuracy. Additionally, we can&rsquo;t apply any kind of feature selection and / or dimensionality reduction without the potential loss of information necessary for producing accurate output values.</p><p>In a nutshell, we solve a difficult regression problem, but there are a number of quirks in our case, namely</p><ol><li>We have an oracle $f$​ (also our target function) that can generate noiseless groundtruth $(x, y)$​​ pairs on the fly.</li><li>$f$​ is extremely discontinuous and changes a ton around discontinuities</li><li>We need to achieve a high degree of precision on the orders of 1e-5 to 1e-7</li><li>$f$ also has 100s of dimensions in its input and output spaces</li></ol><p>Because of these quirks, many approaches have been investigated, and I&rsquo;ll go in depth in the following 4</p><ol><li>Neural Networks</li><li>2nd order optimization of Neural Nets for regression</li><li>Residual-based splitting</li><li>Decision Trees + Neural Nets (DTNN)</li></ol><p>These proved to be the most influential and powerful methods out of all the other tricks and techniques we experimented with.</p><h2 id=neural-networks>Neural Networks<a hidden class=anchor aria-hidden=true href=#neural-networks>#</a></h2><p>Why deep neural nets for an approximation problem?</p><p>If we first consider the naive approach of storing a bunch of pre-computed pairs $(x, f(x))$​​ for all $x$ values in the historical data, we would have a perfect approximator. However, there not only is a ton of historical data (likely on the scale of petabytes), using this as a function to then retrieve a value for a given $x$​​ would take an unreasonably long time. Supposing you used some kind of nearest neighbor weighting model and stored a fraction of the historical data values and reduced the search time to find the $k$ nearest data points necessary for interpolation to reasonable milliseconds, then the accuracy worsens significantly.</p><p>Now suppose we first ignore the discontinuities in our target function, we otherwise have very little information about what the target function is like without having to dive deep into the function&rsquo;s code itself or doing significant data analysis on an extremely complex function. So most attempts to tackle this like a data science problem end up failing here. We need something that is flexible and can capture almost arbitrary patterns in the data.</p><p>Luckily, since the client only cares that all historical data when passed through the approximated function are correct, we don&rsquo;t need to worry about extrapolation, so potentially interpolation algorithms can come into play. We could generate many interpolation points and use interpolation algorithms such as <a href=https://en.wikipedia.org/wiki/Polynomial_interpolation>polynomial interpolation</a>, which in fact get really good approximations. Unfortunately, interpolation algorithms cannot scale when the dimensions increase and they begin to have impossible memory requirements after about as little as 5 dimensions for our particular target function. Trading off accuracy for lower memory requirements is also unfortunately very poor.</p><p>Deep neural nets on the other hand are flexible function approximators and scale much better with dimensions in terms of both memory and compute, and arguably compress information much better than the interpolation algorithms at the cost of spending time training.</p><p>The typical way to use neural nets in a regression problem is to train the neural net over a lot of training data, constantly evaluate it on a held-out validation dataset and select the model that achieves the lowest loss on the validation dataset. In particular, the loss function is the MSE loss function and the optimizer that worked best was Adam. I won&rsquo;t explain much in detail here, but tanh activation turns out to be the best and outperforms any non-smooth activation like ReLU significantly.</p><p>However, standard neural networks on their own are nowhere near sufficient to achieve any level of desirable accuracy in our project, and the next section discusses the first massive improvement in performance via 2nd order optimization.</p><h2 id=2nd-order-optimization>2nd Order Optimization<a hidden class=anchor aria-hidden=true href=#2nd-order-optimization>#</a></h2><p>Almost ubiquitously, deep learning practitioners rely on first-order optimization algorithms such as Gradient Descent, Adam, RMSProp to name a few. These methods prove incredibly useful in many tasks because they are fast, computationally efficient and feasible, often bug-free, and many other reasons listed out in this <a href=https://stats.stackexchange.com/a/394108>stackoverflow answer</a>. Another important aspect of first-order methods is that they achieve low generalization error compared to second-order methods, making algorithms like SGD and Adam incredibly popular in CV and NLP tasks where generalization error is paramount.</p><p>However, some of these aspects are not a problem in our project. Generalization error is less of an issue since we can generate infinite, noiseless data, with the same distribution as test data, and in fact we can control the generalization error by tuning how much data is fed to the model at training time. In a future section when I discuss about the DTNN model, we also don&rsquo;t need as much data as you think to be generated to ensure low generalization error. For similar reasons, in the DTNN model the neural networks trained are generally quite small, so we don&rsquo;t have an issue of scale faced by 2nd order optimization of large neural networks.</p><p>These features of our project suddenly make 2nd order optimization algorithms much more feasible. Since we want to achieve an extremely high level of precision, 2nd order optimization actually becomes necessary.</p><p><a href=https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm>L-BFGS</a> proves to be a very capable and feasible 2nd order algorithm that ended up being used throughout this entire project. The following graph shows as a function of time (s), how L-BFGS compares to Adam, a 1st order method when trying to fit the function $\cos(20x)$​ over $x \in [-1, 1]$ with a small neural network (~40 parameters). The data generated and fed into the neural network mimics that of the actual project. Very quickly L-BFGS converges to a low loss and outperforms Adam considerably.</p><p><img loading=lazy src=assets/lbfgs-vs-adam.png alt=lbfgs-vs-adam></p><p>With 2nd order optimization, a single deep neural net was able to achieve about 30% accuracy on test data in the project, meaning it predicted 30% of data points to within 1 of its true value. But this is about as far as it will go, and can&rsquo;t scale farther in any direction (model complexity, time, data etc.) without entering scaling problems or hitting a minimum. The major issue is that discontinuities reduce the performance of the neural net as it attempts to fit a smooth model over it, in addition to having major approximation errors around the discontinuities. I tackle this issue next.</p><h2 id=residual-based-splittingresidual-based-splitting>Residual-Based Splitting">Residual-Based Splitting<a hidden class=anchor aria-hidden=true href=#residual-based-splittingresidual-based-splitting>#</a></h2><p>We can treat any arbitrary function like our target function as being some piecewise smooth function if you split the input space into the right regions. So one solution is to identify the smooth regions of the input space and train a different function approximator that can achieve high precision and doesn&rsquo;t need to worry about fitting to discontinuities. Thus, the fundamental reason for using a Decision Tree for this problem is to <strong>handle discontinuities</strong>.</p><p>Before diving into how a DT and NN work together, let&rsquo;s first look at the splitting algorithm that drives it.</p><p>To understand how the splitting works to find discontinuities, I&rsquo;ll demonstrate it on a simple one-dimensional discontinuous sine dataset which is shown below.</p><p><img loading=lazy src=assets/disc-sine.png alt=disc-sine></p><p>There&rsquo;s a clear jump discontinuity at around <code>x = 56</code> which would cause regression to be difficult! But let&rsquo;s do a bit of overkill and try fitting a tanh activated neural network with L-BFGS to this data, we generate the following predictions (orange) compared to the ground truth (blue)</p><p><img loading=lazy src=assets/disc-sine-fit.png alt=disc-sine-fit></p><p>Notably, we observe that on the smooth parts of the dataset, the neural network more or less fits it well. However, as we approach the discontinuity the predictions begin to vary a lot and we can see that the neural net attempts to make a smooth connection between the start and end of a discontinuity. Visually it&rsquo;s clear where the discontinuity is, and we can identify this algorithmically by using residuals, which is equal to <code>prediction - ground_truth</code>, and when we plot the residuals we get</p><p><img loading=lazy src=assets/disc-sine-residuals.png alt=disc-sine-residuals></p><p>The residuals are a strong signal of where the model has fitted well and where it hasn&rsquo;t. We can see that the residual magnitude is near 0 on smooth parts, and increases significantly near the discontinuity. We can then clean up this signal further by taking the top 99th percentile of residuals by magnitude, leaving us with the following data points. The red dashed line represents the location of the true discontinuity.</p><p><img loading=lazy src=assets/disc-sine-residuals-99.png alt=disc-sine-residuals-99></p><p>We observe now that amongst the largest residuals, residuals increase in magnitude in the negative direction as we approach the discontinuity before suddenly flipping in sign and decreasing in magnitude as we move away from the discontinuity. This is something that will often happen when fitting smooth models like a neural network with smooth activation to the discontinuity as the model attempts to find a smooth transition around the discontinuity. However, as a result, the residuals will have a sign flip and / or a large increase in magnitude around the discontinuity.</p><p>A direct algorithmic way to then find this discontinuity is to use the splitting algorithm regression DTs use, which is finding a split on one of the input dimensions that minimizes the mean squared error of the 99th percentile residuals. Visibly, we can see that such a split would minimize the MSE by splitting near the discontinuity. This serves as a rather crude (but surprisingly effective) approach to identifying residuals with minimal overhead.</p><p>There can be a lot of further research on discontinuity finding to improve this, from refining a split decided by a DT by generating more data near the split or finding other algorithms that discover and can ignore the noise potentially introduced by poor-fitting in other input space regions, in addition to being more effective in higher dimensions where discontinuities in other dimensions or spanning multiple dimensions can make this much more complex.</p><h2 id=dtnns>DTNNs<a hidden class=anchor aria-hidden=true href=#dtnns>#</a></h2><p>Now that we have in our toolbox a neural network-based function approximator and a method to identify discontinuities and separate out the smooth regions in the input space, we can combine these into a single decision tree neural network model. This combination then allows us to also make effective use of a key property of this problem, which is that we can <strong>generate data on the fly</strong> using the target function.</p><p>At a high level, a DTNN is a decision tree with neural nets at each leaf that perform the regression for any data that falls to that leaf, and the splitting algorithm is the residual-based splitting method. Thanks to the splitting of the input space, we also don&rsquo;t need as much data or as big of a neural network model at each leaf to sufficiently capture the behavior there with high accuracy.</p><h3 id=growing-the-dtnn>Growing the DTNN<a hidden class=anchor aria-hidden=true href=#growing-the-dtnn>#</a></h3><p>The growing algorithm is quite similar to a typical decision tree growing algorithm but with a few changes. The DTNN maintains the same procedure of taking each leaf node and determining first whether to continue splitting, then deciding on the best split to make before making the split.</p><p>One key difference is that every leaf has an associated neural network that does the prediction for all data that falls into that leaf&rsquo;s data range (the subset of the input space it represents). Note that each leaf is associated with a disjoint subset of the input space of the target function, and the union of all these disjoint subsets forms the entire input space (up to the boundaries set for interpolation).</p><p>For leaf node splitting, the residual-based splitting method introduced earlier is used and the residuals are computed using the trained neural net associated with the leaf. Importantly, since we can generate infinite data, this model can become infinitely precise to the point it memorizes every input output pair via splitting the input space into extremely data ranges. Thus, we only split leaf nodes where the neural network trained there is not accurate enough. Ideally, this neural network reduces the need to memorize every value and learns a good approximation with fewer parameters.</p><p>For each new leaf produced after splitting an old leaf, we create a new associated neural net. These new neural nets are copies of the neural net associated with the old leaf, helping speed up training with a warm start.</p><p>Lastly, we regenerate data in each new leaf, using randomly selected inputs data points that fall within the new leaf&rsquo;s data range, and train the neural net on that new data.</p><p>Visually, growing a DTNN looks like this:</p><p><img loading=lazy src=./assets/dtnn_growth.gif alt="Visualization of a DTNN training"></p><p>A green circle represents a leaf node that has a trained neural network that is accurate enough, a blue node is an internal node or a to be trained leaf node. Each round, we increase the depth of the tree by one via residual-based splitting and only generate two children per leaf node, and then fine tune the neural nets at all leaf nodes that need fine tuning.</p><h3 id=dtnn-pseudocode>DTNN Pseudocode<a hidden class=anchor aria-hidden=true href=#dtnn-pseudocode>#</a></h3><p>For those who prefer pseudocode, the growing algorithm is as follows</p><pre tabindex=0><code class=language-pseudocode data-lang=pseudocode>def DTNNGrow(rounds, train_net, data_generator, pass_criteria, splitting_func, input_subspace):
    root_node := initialize a DTNN with a empty root node associated with input_subspace
    leafs_to_train = { root_node }
    passing_leafs = {}
    for round = 1 to round = rounds:
        if leafs_to_train is empty:
            return root_node
        for leaf in leafs_to_train:
            # generate data within the subset of the input space of data that falls in the leaf
            train_data, test_data := data_generator(leaf.data_range)
            if leaf has a parent node:
                neural_net := copy of neural net in parent node
            else:
                neural_net := initialize a new neural net
            # train a NN until its good enough or until some max iterations
            train_net(neural_net, train_data, test_data)
            remove leaf from leafs_to_train
            if pass_criteria(neural_net, test_data):
                add leaf to the set passing_leafs
            else:
                # split the subspace of the current leaf based on the trained NN and train_data
                data_ranges := splitting_func(neural_net, train_data, leaf.data_range)
                for data_range in data_ranges:
                    new_leaf := initialize a new leaf node associated with data_range
                    add new_leaf to the set leafs_to_train
		return root_node
</code></pre><p>We grow the DTNN in rounds, with each round increasing the depth of the DTNN by 1. To train, you provide the number of training rounds, a neural net training function, the data generator, a pass criteria function, and a splitting function.</p><p>The neural net training function <code>train_net</code> should take a neural net, training data, and test data generated from the <code>data_generator</code> that is within a leaf&rsquo;s data range, and train that neural net. Usually, this stops training when the neural net is accurate enough, or when it is training for too long.</p><p>The <code>data_generator</code> will usually be a wrapper function around the target function we want to approximate where it takes a data range and produces training and test data that is within that data range. Our experiments used uniform sampling across each input dimension of the data range, but I actually recommend using something akin to <a href=https://jskhu.github.io/fps/3d/object/detection/2020/09/20/farthest-point-sampling.html>farthest point sampling</a> (common sampling technique in 3D computer vision like sampling point clouds).</p><p>The <code>pass_criteria</code> function will evaluate a neural net over the given test data and would return <code>true</code> if the neural net is good enough and <code>false</code> otherwise. This function is important since the data is noiseless and infinitely generatable, so theoretically you can always keep improving but we need to stop eventually.</p><p>The <code>splitting_func</code> is a function that when given the neural network, the training data, and the data range the training data is generated from, returns the new data ranges for all new leaves. An example would be the residual-based splitting method.</p><p>The <code>input_subspace</code> is simply the data range of inputs that we want to approximate the target function over, and the root node of the DTNN is associated with this input subspace. For our project, this would be the boundaries of every feature dimension in the historical data.</p><h3 id=dtnn-discussion>DTNN Discussion<a hidden class=anchor aria-hidden=true href=#dtnn-discussion>#</a></h3><h4 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h4><p>With the DTNN and residual-based splitting and 2nd order optimization, we raised that 30% to about 86% of test data points approximated to within 1, despite data points being on the order of 1e5 to 1e7. In particular, the single NN and DTNN were both trained on a single CPU for 64 hours and achieved 30% and 86% accuracy respectively. This outperforms just about any regression model we tried, from GBDTs (~2% accuracy), to first-order optimized neural nets (~2% accuracy), to interpolation algorithms (infeasible).</p><p>The major reason the DTNN achieves such a massive improvement is in addition to 2nd order optimization, it also can <strong>effectively leverage the data generating aspect of the problem</strong> in an efficient distributed manner via a decision tree structure. Intuitively, each split at a leaf reduces the data range for the new leaves, meaning less data is necessary to be kept around in memory to achieve low generalization error, and effectively optimize a neural network as well. Models that can&rsquo;t leverage the data generation will have to rely on generating a huge amount of data that can barely fit in memory or augmenting data every round. Even with some kind of data generation mimicking that of the DTNN where data is effectively generated for leaves that need more training / high error regions in the input space, models like single neural nets will need to not only be massive, but also somehow solve the issue of <a href=https://en.wikipedia.org/wiki/Catastrophic_interference>catastrophic forgetting</a>.</p><p>The DTNN also has a number of nice properties. One is that it is highly scalable compared to neural networks, another is that it has unbounded performance potential with no generalization problems (usually). There are a bunch more but these are listed in the <a href=#Further-Applications>further applications section</a>. There&rsquo;s also a <a href=#Further-Research-Topics>further research topic section</a> that lists out a number of questions my advisor and I asked that we didn&rsquo;t have time to explore but are probably worth exploring and can improve the results.</p><h4 id=scaling>Scaling<a hidden class=anchor aria-hidden=true href=#scaling>#</a></h4><p>You can easily parallelize the DT growing process by training each leaf on a separate core, subject to balancing issues if there are only 2 leaves training and one takes a lot longer than the other. Moreover, this project is more often CPU bottlenecked as the target function tends to be the main limiting factor due to data generation speeds, so GPUs aren&rsquo;t really necessary (nor are 2nd order optimization methods that well optimized on the GPU), so in terms of scaling, you can simply increase the number of CPUs (generally quite easy) and achieve pretty high efficiency in training speed vs number of CPUs used.</p><p>You can even horizontally scale this process across multiple servers probably, although I&rsquo;m not exactly sure how much of an overhead that might have. I suspect it should be fairly low since the only unique data each different server has is the data range and the neural network, everything else is the same from the target function / data generator, to the neural network architecture and splitting function.</p><h4 id=unbounded-potential>Unbounded Potential<a hidden class=anchor aria-hidden=true href=#unbounded-potential>#</a></h4><p>In theory, with a target function at hand to generate noiseless training data, the DTNN can get <strong>100% of training and test data points approximated to not just within 1, but even 0.1, 0.01, etc.</strong> when given sufficient time, a guarantee that cannot be said of any other model that I&rsquo;m aware of (except for an extremely, out of memory, DT kind of model which at that point is really just memorizing the training data).</p><p>This is thanks to the fact that the test data will always be &ldquo;in distribution&rdquo; since it&rsquo;s generated from the same function as the training dataset (and generally mimics the historical data the client has). As long the neural network at each leaf is given sufficient data points, it will have minimal to no generalization error.</p><p>Moreover, every split on the data range makes training neural nets easier and easier as you effectively cut the hard part of the regression problem out and leave just the smoother regions of data. This is an easy direct way of adding parameters to the model to boost performance without making a neural network bigger and scales linearly with each leaf added.</p><h2 id=further-applications>Further Applications<a hidden class=anchor aria-hidden=true href=#further-applications>#</a></h2><p>In addition to just solving the formal problem of approximating a target function with high accuracy and precision, there are a number of other applications of this since we effectively turn lines of code that form the target function into matrices! Here is a non-exhaustive list of some of these applications</p><ul><li><strong>Function compression:</strong> Reduce the amount of space required for purpose of approximation. Moreover, the calculator that was being approximated in my project actually pulls data from various tables and the neural nets are capable of removing the need for that data and bake that information into their model parameters</li><li><strong>Faster computations:</strong> speed up an existing function with a faster model that approximates it. Easily trading off accuracy for speed.</li><li><strong>Differentiation:</strong> Differentiate a handwritten function for analysis purposes. Derivative information is often useful for many problems such as optimization. My advisor had the idea of potentially trying to determine which other calculators in our client&rsquo;s old system were most similar to the one we approximated and first-order information would be helpful in determining this.</li><li><strong>Portability:</strong> A decision tree and their neural networks can be easily packaged as some matrices in a single data file which can easily be run anywhere without needing access to sensitive files and data.</li><li><strong>Security:</strong> A file containing just matrices makes people very comfortable compared to a calculator with 1000s of lines of code and poses a minimal security risk should these matrices get stolen as business logic cannot be read from them.</li></ul><h2 id=further-research-topics>Further Research Topics<a hidden class=anchor aria-hidden=true href=#further-research-topics>#</a></h2><p>We faced a number of interesting problems in an effort to approximate our target function, all of which may benefit from additional research to improve training time, accuracy etc.</p><p><strong>Handling discrete/continuous:</strong> Discontinuity finding may differ when the input dimension is discrete or continuous. Perhaps some kind of bisection search method may find the true discontinuity with high precision and accuracy or using some form of refinement procedure to fine tune a split on a continuous axis.</p><p><strong>Non-linear/non-axial discontinuities:</strong> In higher dimensions, discontinuities may not be axial and may be non-linear. While these discontinuities can sometimes be approximated by several axial/linear splits on the input data space range, there are likely more efficient methods that allow for non-linear splits that can cover a wider range of potential discontinuities. One method might be to replace the splitting function with a neural net trained to perform &ldquo;split classification&rdquo;. Not only does this enable non-linear splits, but it would also make the entire DTNN model end to end learnable and differentiable which could have potentially interesting results.</p><p><strong>Data generating given non-linear/non-axial splits:</strong> Supposing the above problem was dealt with and we now have a splitting function that effectively classifies a data point as being one of <code>k</code> classes. How do we generate data for each of these classes?</p><p><strong>Adaptive data generation:</strong> When not enough data is provided for training, a model will get a high generalization error which is not desirable. However, when too much data is provided, the marginal improvement in generalization error is likely not worth the amount of extra training time required. Thus, there is probably some kind of optimal data generation amount at each leaf of the DTNN.</p><p><strong>Adaptive early stopping:</strong> Notably, just increasing the total number of training iterations per leaf does not necessarily correlate with a better model when training for the same total amount of time as a model can begin to struggle due to discontinuities. Empirically, too many iterations makes the model spend too much time trying to approximate discontinuities when it is better off performing a split first, then training for much longer. Can we somehow optimally determine when to perform a split to deal with discontinuities?</p><h2 id=closing-notes>Closing Notes<a hidden class=anchor aria-hidden=true href=#closing-notes>#</a></h2><p>I had a great time at QuantCo and working with my advisor on this problem. If you are ever interested in the craziest engineering, machine learning, data science, etc. problems, pay them a visit. Or if you like good company and food, they&rsquo;re also a great place.</p><p>🌊</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.stoneztao.com/tags/ai/>AI</a></li><li><a href=https://blog.stoneztao.com/tags/decision-trees/>Decision Trees</a></li></ul><nav class=paginav><a class=prev href=https://blog.stoneztao.com/posts/jax-for-torch-users/><span class=title>« Prev</span><br><span>My 1st post</span></a>
<a class=next href=https://blog.stoneztao.com/posts/ai-challenge-survey/><span class=title>Next »</span><br><span>A Survey of AI Programming Challenges</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share High Precision Function Approximation With Decision Trees and Neural Networks on twitter" href="https://twitter.com/intent/tweet/?text=High%20Precision%20Function%20Approximation%20With%20Decision%20Trees%20and%20Neural%20Networks&url=https%3a%2f%2fblog.stoneztao.com%2fposts%2fnn-fnc-approx%2f&hashtags=AI%2cDecisionTrees"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share High Precision Function Approximation With Decision Trees and Neural Networks on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fblog.stoneztao.com%2fposts%2fnn-fnc-approx%2f&title=High%20Precision%20Function%20Approximation%20With%20Decision%20Trees%20and%20Neural%20Networks&summary=High%20Precision%20Function%20Approximation%20With%20Decision%20Trees%20and%20Neural%20Networks&source=https%3a%2f%2fblog.stoneztao.com%2fposts%2fnn-fnc-approx%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share High Precision Function Approximation With Decision Trees and Neural Networks on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fblog.stoneztao.com%2fposts%2fnn-fnc-approx%2f&title=High%20Precision%20Function%20Approximation%20With%20Decision%20Trees%20and%20Neural%20Networks"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share High Precision Function Approximation With Decision Trees and Neural Networks on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fblog.stoneztao.com%2fposts%2fnn-fnc-approx%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share High Precision Function Approximation With Decision Trees and Neural Networks on whatsapp" href="https://api.whatsapp.com/send?text=High%20Precision%20Function%20Approximation%20With%20Decision%20Trees%20and%20Neural%20Networks%20-%20https%3a%2f%2fblog.stoneztao.com%2fposts%2fnn-fnc-approx%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share High Precision Function Approximation With Decision Trees and Neural Networks on telegram" href="https://telegram.me/share/url?text=High%20Precision%20Function%20Approximation%20With%20Decision%20Trees%20and%20Neural%20Networks&url=https%3a%2f%2fblog.stoneztao.com%2fposts%2fnn-fnc-approx%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://blog.stoneztao.com/>Stone's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>